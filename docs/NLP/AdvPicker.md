---
title: æœªæ ‡æ³¨ç›®æ ‡è¯­æ–™æ˜¯å¦å‡é€‚åˆç”¨äºè·¨è¯­è¨€å­¦ä¹ ?ã€åŸºäºå¯¹æŠ—åˆ¤åˆ«å™¨é«˜æ•ˆåˆ©ç”¨æœªæ ‡æ³¨è¯­æ–™çš„è·¨è¯­è¨€NERç®—æ³•AdvPickerã€
date: 2021-08-01 11:43:21
tags: [NLP/IE/Cross-lingual NER, ML/Adverial Learning]
description: Empower Entity Set Expansion via LM Probing
---

(å†è¿‡å‡ ä¸ªå°æ—¶ä»Šå¹´çš„ ACL å°±è¦æ¥äº†ï¼Œèµ¶åœ¨ ddl ä¹‹å‰ï¼Œ

ç®€å•ä»‹ç»ä¸€ä¸‹éŸ¦ä¹ï¼Œæˆ‘ï¼Œåƒæƒ ï¼ŒBÃ¶rjeï¼ŒYi Guan ç­‰äººåœ¨ ACL21 ä¸Šçš„è¿™ç¯‡å·¥ä½œã€‚

[AdvPicker: Effectively Leveraging Unlabeled Data via Adversarial Discriminator for Cross-Lingual NER](https://aclanthology.org/2021.acl-long.61) (ACL-IJCNLP 2021)

âœï¸*Weile Chen, Huiqiang Jiang, Qianhui Wu, BÃ¶rje F. Karlsson, Yi Guan*.

ğŸ‘¨â€ğŸ’» Code in [Github](https://aka.ms/AdvPicker)

## Motivation

äº‹å®ä¸Šï¼Œç»æµå®åŠ›æ³¨å®šä¼šå½±å“æ‰€æœ‰ç§‘æŠ€æŠ€æœ¯å‘å±•çš„è¿›ç¨‹ã€‚
å¯¹äºå¦‚ä»Šå¤§ç«çš„æ ‡æ³¨èµ„æºæ•æ„Ÿå‹çš„ä¸€ç³»åˆ—æ·±åº¦å­¦ä¹ ä»»åŠ¡ï¼Œè¿™ç§å†²çªæ›´ä¸ºæ˜æ˜¾ã€‚
è¿ç§»å­¦ä¹ ã€è‡ªå­¦ä¹ ã€å¯¹æ¯”å­¦ä¹ ç­‰æ–¹æ³•æœ‰æ•ˆè§£å†³äº†å¾ˆå¤§ä¸€éƒ¨åˆ†é—®é¢˜ï¼Œä½†è¿™äº›æ–¹æ³•å¾€å¾€éœ€è¦å¤§é‡æ•°æ®ï¼Œä¸”ä»…é€‚ç”¨äºå°‘é‡ä»»åŠ¡æˆ–è€…ä¸èƒ½å®Œå…¨è§£å†³ä¸‹æ¸¸ä»»åŠ¡é—®é¢˜ã€‚

è€Œåœ¨æ‹¥æœ‰ä¸°å¯Œé«˜è´¨é‡çš„è‹±è¯­è¯­æ–™ä¸‹(å…¶å®è¿˜æ˜¯å°‘æ•° domain)ï¼ŒFLAT NER ä»»åŠ¡å·²ç»èƒ½å¤Ÿåšåˆ°æ¯”è¾ƒé«˜çš„å‡†ç¡®ç‡ï¼Œå¦‚ä½•å°†è¿™ç§èƒ½åŠ›åˆé€‚çš„è¿ç§»åˆ°å…¶ä»–ä½èµ„æºï¼Œç”šè‡³æ— èµ„æºçš„ç›®æ ‡è¯­è¨€ä¸­ï¼Œæ˜¯ä¸€ä¸ªå¾ˆæœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚
ä¹‹å‰çš„å·¥ä½œæŒ‰ç…§ç®—æ³•è®¾è®¡è§’åº¦ï¼Œå¯ä»¥åˆ†ä¸ºç€é‡æ„é€ ä¸€ä¸ªèƒ½å¤Ÿæ‰‘æ‰è·¨è¯­è¨€ç‰¹å¾çš„æ¨¡å‹çš„ Feature-based methods å’Œç€é‡æ„é€ ç›®æ ‡è¯­è¨€æ•°æ®æ ‡æ³¨çš„ Labeling-based methodsã€‚
å…¶ä¸­ï¼ŒFeature-based methods å¯ä»¥é€šè¿‡ mBERTã€Meta-learningã€Adapter ç­‰æ–¹å¼å®ç°ï¼ŒLabeling-based methods åˆå¯åˆ†ä¸º Soft-label å’Œ Hard-labelï¼Œå¯é€šè¿‡é¢„è®­ç»ƒå¥½çš„ç¿»è¯‘æ¨¡å‹ï¼Œä¹Ÿå¯é€šè¿‡åˆ©ç”¨ Distillation æ¥å®ç°ã€‚

ä½†æ˜¯è¿™äº›æ–¹æ³•éƒ½å‡è®¾æ‰€æœ‰æœªæ ‡æ³¨è¯­æ–™éƒ½å…·æœ‰è¿™ç§è·¨è¯­è¨€ç‰¹æ€§ï¼Œéƒ½é€‚åˆæ¥åšè¿ç§»å­¦ä¹ ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æ”¾çš„é—®é¢˜ã€‚
æˆ‘ä»¬ç›´è§‰å‘Šè¯‰æˆ‘ä»¬å°±å¦‚åŒé«˜è´¨é‡æ ‡æ³¨æ•°æ®ä¹Ÿå­˜åœ¨å¤§é‡å™ªå£°ä¸€æ ·(å¯ä»¥ç”¨ Co-teaching çš„æ–¹å¼æ¥è§£å†³)ï¼Œæœªæ ‡æ³¨ç›®æ ‡è¯­è¨€æ•°æ®ä¹Ÿä¸åº”è¯¥å…¨éƒ¨é€‚ç”¨è·¨è¯­è¨€è®­ç»ƒä¸­ã€‚

æœ¬æ–‡çš„ç›®æ ‡æ˜¯è®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿä¸æ¨¡å‹è•´å«çš„ä¸è¯­è¨€æ— å…³ç‰¹å¾ä¸€è‡´çš„æ•°æ®åˆ¤åˆ«å™¨ã€‚

## AdvPicker

<center><img width="700" src="https://cdn.nlark.com/yuque/0/2021/png/104214/1627717193323-ef3686c6-8bcc-4161-9231-37a83670bdea.png?x-oss-process=image%2Fresize%2Cw_1504"></center>

å¦‚ä½•å»æ„é€ è¿™æ ·çš„ä¸€ä¸ªåˆ¤åˆ«å™¨ï¼Ÿæ—¢ç„¶æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ‰‘æ‰ **Language-independent** çš„ä¿¡æ¯ï¼Œé‚£ä¹ˆå°±åº”è¯¥è®©æ¨¡å‹é¿å…æ‹¥æœ‰ **Language-specific** çš„èƒ½åŠ›ã€‚

è¿™ç§èƒ½åŠ›åˆå¦‚ä½•æ¥è¡¡é‡å‘¢ï¼Ÿé¦–å…ˆï¼Œæˆ‘ä»¬æƒ³åˆ°çš„æ˜¯å¦‚æœ freeze æ‰æ¨¡å‹çš„å‚æ•°ï¼Œåœ¨æ¨¡å‹ä¸‹æ¸¸åŠ ä¸€ä¸ª FFN å»åšåˆ¤æ–­è¯­æ–™æ¥æºä»»åŠ¡(2 åˆ†ç±»ä»»åŠ¡ï¼Œ0-æºè¯­æ–™ï¼Œ1-ç›®æ ‡è¯­æ–™)ï¼Œå¦‚æœæ¨¡å‹èƒ½å¾ˆå®¹æ˜“åˆ¤æ–­è¿™ä¸ªä»»åŠ¡çš„è¯ï¼Œå°±è¯´æ˜æ¨¡å‹å¯¹äº **Language-specific** çš„ç‰¹å¾å­¦ä¹ çš„å¾ˆå¥½ã€‚

ç®€å•åœ¨ mBERT å’Œæºè¯­è¨€ä¸Š Fine-tune çš„ mBERT-ft ä¸¤ä¸ªæ¨¡å‹ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œå¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚

`\begin{array}{c|cccc} \hline & \textbf{de} & \textbf{es} & \textbf{nl} & \textbf{Avg} \\ \hline \text{mBERT} & 99.08\% & 99.66\% & 98.98\% & 99.24\% \\ \text{mBERT-ft} & 98.38\% & 98.66\% & 97.27\% & 98.10\% \\ \text{mBERT-TLADV} & 79.62\% & 82.89\% & 77.45\% & 79.99\% \\ \hline \end{array}`

ä¸Šè¿°å®éªŒè¯´æ˜(å…ˆå¿½ç•¥ç¬¬ä¸‰è¡Œ)ï¼Œåœ¨é»˜è®¤æˆ–è€… Fine-tune æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ‹¥æœ‰æå¼ºçš„ Language-specific èƒ½åŠ›ã€‚
è¿™ä¹Ÿå°±å¯¼è‡´äº†ç›´æ¥æ‹¿æ¥åšè¿ç§»å­¦ä¹ çš„è¯ï¼Œä¼šå¯¼è‡´ Student Model å­¦ä¹ åˆ°çš„åŸºæœ¬ä¸Šéƒ½æ˜¯ Langauge-specific ç‰¹å¾ï¼Œè¿™ä¸æ˜¯æˆ‘ä»¬æƒ³çœ‹åˆ°çš„ã€‚

å¦‚ä½•å»é™ä½è¿™ç§æºæ¨¡å‹å¯¹äº Language-specific ç‰¹å¾è¿‡äºæ•æ„Ÿçš„æƒ…å†µï¼Œæˆ‘ä»¬æƒ³åˆ°çš„æ˜¯åˆ©ç”¨å¯¹æŠ—å­¦ä¹ +å¤šä»»åŠ¡ï¼Œä½¿å¾—æºæ¨¡å‹åœ¨æºè¯­è¨€ä¸Šåš Fine-tune çš„åŒæ—¶, å¼`$(\ref{equ:ner})$`ï¼Œå¯¹æŠ—çš„å»å­¦ä¹ ä¸€ä¸ª Token ç²’åº¦çš„è¯­è¨€åˆ¤åˆ«å™¨(Token-levl Adv, TLADV), å¼`$(\ref{equ:dis})$`ï¼Œå³æ¨¡å‹æµç¨‹å›¾çš„å›¾(a)éƒ¨åˆ†ã€‚
æ•´ä½“ç›®æ ‡å°±æ˜¯ä½¿å¾—æ¨¡å‹å³å­¦ä¹ åˆ° Task-specific çš„ NER ç‰¹å¾ï¼Œåˆèƒ½é™ä½å­¦ä¹ æºè¯­è¨€ Specific çš„ç‰¹å¾ã€‚

`\begin{equation} \mathcal{P}_{\theta}({\boldsymbol{Y}}^{\text{NER}}) = \text{softmax}(\boldsymbol{W}^{\text{NER}}\boldsymbol{h} + \boldsymbol{b}^{\text{NER}}) \label{equ:ner} \end{equation}`

`\begin{equation} \mathcal{P}_{\theta}({\boldsymbol{Y}}^{\text{DIS}}) = \sigma(\boldsymbol{W}^{\text{DIS1}}\text{ReLU}(\boldsymbol{W}^{\text{DIS2}} \boldsymbol{h})) \label{equ:dis} \end{equation}`

å…¶ä¸­`$\boldsymbol{h} = {\boldsymbol{E}}(\boldsymbol{x})$`ä¸º Encoder, `$\boldsymbol{W}^{\text{x}}$`ä¸ºå¯å­¦ä¹ å‚æ•°, `$\mathcal{P}_{\theta}({\boldsymbol{Y}}^{\text{X}})$`ä¸ºä»»åŠ¡è¾“å‡ºæ¦‚ç‡ä¼°è®¡ã€‚

ğŸ¤¦ ä¸€å¼€å§‹æƒ³çš„æŒºç¾å¥½çš„ï¼Œä½†æ˜¯ Adversarial Learning çš„è°ƒå‚è¿‡äºç„å­¦ï¼Œæ­¤å¤„çœç•¥æ— æ•°å®éªŒ workï¼Œä¹Ÿè®¸ä»¥åå¯ä»¥ç”¨ NNI è¿™ç§æ¥å®Œæˆè¿™ç§å·¥ä½œã€‚

å®Œæˆä¸Šè¿°å·¥ä½œä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥è·å¾—ä¸€ä¸ªåœ¨æºè¯­è¨€ä¸Š Fine-tune å¥½çš„ NER æ¨¡å‹å’Œä¸€ä¸ªè¯­è¨€åˆ¤åˆ«å™¨(å…±äº«ä¸€ä¸ª mBERT)ã€‚
æ­¤æ—¶æ‹¿ mBERT-TLADV å»åšä¸Šè¿°è¯­æ–™æ¥æºä»»åŠ¡ï¼Œè¿™ä¸ªæ—¶å€™å®ƒä¹‹ä¸­çš„ Language-specific çš„ç‰¹å¾å°±ä¼šæ˜æ˜¾å‡å°‘ã€‚

è¿™ä¸ªæ—¶å€™å¦‚æœæˆ‘ä»¬æ‹¿ mBERT-TLADV å»åšç±»ä¼¼ UniTrans çš„ Distillation å­¦ä¹ ï¼Œå…¶å®å·²ç»æ˜¯ä¸€ç¯‡å·¥ä½œäº†ã€‚
ä½†æ˜¯æˆ‘ä»¬ç»§ç»­æƒ³ï¼Œå­¦ä¹ å¾—åˆ°çš„ NER æ¨¡å‹å’Œåˆ¤åˆ«å™¨è¿˜æœ‰ä»€ä¹ˆç”¨å¤„ã€‚

å¯¹æŠ—å­¦ä¹ çš„ç›®çš„æ˜¯æ¨¡å‹åˆ¤æ–­ä¸å‡ºæ¥è¯­æ–™çš„æ¥æºï¼Œé‚£ä¹ˆå¯¹äºåˆ¤åˆ«å™¨å­¦çš„æ¯”è¾ƒå¥½çš„æ•°æ®(è¿™é‡Œåº”è¯¥æ˜¯è¾“å‡ºæ¦‚ç‡æ¥è¿‘ 0.5 å·¦å³çš„, å¼`$(\ref{equ:l-score})$`)ï¼Œæ‰€æ‹¥æœ‰çš„ Language-independent ä¿¡æ¯ç›¸å¯¹å«é‡(ç›¸å¯¹äºå­¦ä¹ å¾—åˆ°çš„ NER æ¨¡å‹è€Œè¨€)å°±ä¼šåé«˜ã€‚
é‚£ä¹ˆæˆ‘ä»¬ç”¨è¿™éƒ¨åˆ†æ¥åš Distillation çš„è¯ï¼Œè·¨è¯­è¨€å­¦ä¹ æ³›åŒ–æ€§åº”è¯¥æ›´å¥½ã€‚
è¿™å°±æ˜¯æ¨¡å‹æ¶æ„å›¾ä¸­çš„å›¾(b)å’Œå›¾(c)éƒ¨åˆ†ã€‚
å½“æˆ‘ä»¬æ‹¿åˆ°è¿™éƒ¨åˆ†è¯­æ–™å­é›†`$\mathbb{D}_{\text{subset}} = \{x^{\text T}_{\text{subset}}, \boldsymbol{\hat{y}}^{\text{T-NER}}_{\text{subset}}\}$`ä¹‹åï¼Œåˆ©ç”¨æºè¯­è¨€ä¸Š Fine-tune å¾—åˆ°çš„ NER æ¨¡å‹æ ‡æ³¨ä¸Šå¯¹åº”çš„ soft labelï¼Œä¾¿æ„é€ å¥½ç›¸å¯¹åº”çš„æ•°æ®ã€‚

`\begin{equation} \ell_{\text{score}}(\boldsymbol{x}^{\text{T}}) = 1- \left\|\mathcal{P}_{\theta}({\boldsymbol{Y}}^{\text{DIS}}, \boldsymbol{x}^{\text{T}}) - 0.5\right\| \label{equ:l-score} \end{equation}`

çŸ¥è¯†è’¸é¦éƒ¨åˆ†å³ä½¿ç”¨åœ¨æºè¯­è¨€ä¸Š Fine-tune ä¹‹åçš„ NER æ¨¡å‹ä½œä¸º Teacher æ¨¡å‹`$\boldsymbol{h}$`ï¼Œåœ¨ç›®æ ‡è¯­è¨€ä¼ªæ ·æœ¬å­é›†ä¸Šå­¦ä¹ ä¸€ä¸ªç›®æ ‡è¯­è¨€ Student æ¨¡å‹`$\boldsymbol{h}^{\text{T}}_{\text{stu}}$`ã€‚
å…¶æŸå¤±å‡½æ•°ä¸ºå¼`$(\ref{equ:loss-each})$`ã€‚

`\begin{equation} \mathcal{P}_{\theta}({\boldsymbol{Y}}^{\text{T-NER}}) = \text{softmax}(\boldsymbol{W}^{\text{T-NER}}\boldsymbol{h}^{\text T}_{\text{stu}} + \boldsymbol{b}^{\text{T-NER}}) \label{equ:p_stu} \end{equation}`

`\begin{equation} \mathcal L^{\text{KD}} = \frac{1}{N} \sum_{i \in [1, N]} (\mathcal{P}_{\theta}({\boldsymbol{Y}}^{\text{T-NER}}) - \boldsymbol{\hat{y}}^{\text{T-NER}}_{\text{subset}}) ^ 2 \\ \label{equ:loss-each} \end{equation}`

## Experiments

åœ¨ CoNLL è¯­æ–™ä¸Šï¼Œå¯¹è‹±è¯­[en], è¥¿ç­ç‰™è¯­[es], è·å…°è¯­[nl]å’Œå¾·è¯­[de]å››ç§è¯­è¨€è¿›è¡Œæµ‹è¯•ã€‚
å…¶ä¸­è¿™äº›æ•°æ®é›†çš„ label éƒ½æ˜¯ç›¸åŒçš„å››ç§ PER, LOC, ORG, MISCã€‚
é™¤è‹±è¯­ä¸ºæœ‰æ ‡æ³¨æ•°æ®ï¼Œå…¶ä»–è¯­è¨€å‡ä¸ºæœªæ ‡æ³¨è¯­æ–™ã€‚
é€‰ç”¨ mBERT-base ä½œä¸º backboneï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œfreeze embedding layer å’Œåº•ä¸‹ä¸‰å±‚ Transformer å‚æ•°ã€‚
è¶…å‚æ•°`$\mathbb{D}_{\text{subset}}$`å­é›†çš„ç­›é€‰é˜ˆå€¼`$\rho$`è®¾å®šä¸º 0.8ã€‚
(å…¶ä»–è®­ç»ƒç»†èŠ‚è¯¦è§ paper)

`\begin{array}{c|cccc} \hline & \textbf{de} & \textbf{es} & \textbf{nl} & \textbf{Avg} \\ \hline \text{Beto} & 69.56\% & 74.96\% & 77.57\% & 73.57\% \\ \text{mBERT-ADV} & 71.9\% & 74.3\% & 77.6\% & 74.60\% \\ \text{Meta-Cross} & 73.16\% & 76.75\% & 80.44\% & 76.78\% \\ \text{UniTrans*} & 73.61 \pm 0.39\% & \underline{77.3} \pm 0.78 \% & \underline{81.2} \pm 0.83 \% & \underline{77.37} \pm 0.67 \% \\ \hline \text{mBERT-ft} & 72.59 \pm 0.31 \% & 75.12 \pm 0.83 \% & 80.34 \pm 0.27 \% & 76.02 \pm 0.47 \% \\ \text{mBERT-TLADV} & \underline{73.89} \pm 0.56 \%& 76.92 \pm 0.62 \% & 80.62 \pm 0.56 \% & 77.14 \pm 0.58 \%\\ \textbf{AdvPicker} & \textbf{75.01} \pm 0.50 \% & \textbf{79.00} \pm 0.21 \% & \textbf{82.90} \pm 0.44 \% & \textbf{78.97} \pm 0.38 \%\\ \hline \end{array}`

ä¸Šè¡¨å±•ç¤ºäº†éƒ¨åˆ† Baselines å’Œä¸€äº›å¯¹æ¯”å®éªŒç»“æœã€‚
è€ƒè™‘åˆ° UniTrans ä¸­ä½¿ç”¨äº†å¤–éƒ¨ç¿»è¯‘æ¨¡å‹æ•°æ®ï¼Œä¸ºäº†å…¬å¹³æ¯”è¾ƒï¼Œæ­¤å¤„æ¯”è¾ƒçš„æ˜¯ UniTrans å‡ºå»ç¿»è¯‘ä¿¡æ¯çš„ç»“æœã€‚
è¡¨ä¸­ä¸‹åˆ’çº¿éƒ¨åˆ†ä¸ºå¯¹åº”è¯­è¨€ç¬¬äºŒå¥½çš„ç»“æœã€‚
å¯ä»¥çœ‹å‡º AdvPicker åœ¨åªä½¿ç”¨æºè¯­è¨€æ ‡æ³¨æ•°æ®å’Œç›®æ ‡è¯­è¨€æ— æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œè¶…è¿‡äº†ç›®å‰å­˜åœ¨çš„æ‰€æœ‰æ–¹æ³•ã€‚
å’Œä¹‹å‰ SOTAï¼ŒUniTrans\*å¯¹æ¯”åˆ†åˆ«åœ¨å¾·è¯­ä¸Šè¶…è¿‡äº† 1.41%ï¼Œåœ¨è·å…°è¯­ä¸Šè¶…è¿‡äº† 1.71%ã€‚
å³ä½¿æ˜¯å’Œä½¿ç”¨äº†å¤–éƒ¨ç¿»è¯‘æ•°æ®çš„ UniTransï¼ŒAdvPicker ä¹Ÿæ˜¯å¯æ¯”è¾ƒçš„ï¼Œåœ¨å¹³å‡ F1 ä¸­ä»…å·®å¼‚ 0.04ã€‚
ç›¸å¯¹äº mBERT-ft å’Œ mBERT-TLADV åœ¨ F1 å€¼ä¸Šåˆ†åˆ«æå‡äº† 2.95%å’Œ 1.83%ã€‚

è™½ç„¶ä¸Šè¿°ç»“æœå¯ä»¥è¯´æ˜ AdvPicker åœ¨ Cross-lingual NER ä»»åŠ¡ä¸Šå¯ä»¥å–å¾—å¾ˆä¸é”™çš„æ•ˆæœï¼Œä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯æƒ³æ·±å…¥æ¢ç©¶è¿™æ ·çš„æ“ä½œåˆ°åº•æ”¹å˜äº†ä»€ä¹ˆã€‚
é¦–å…ˆæˆ‘ä»¬å¯¹å¯¹æŠ—åˆ¤åˆ«å™¨ï¼Œç­›é€‰å¾—åˆ°çš„ç›®æ ‡è¯­è¨€ Train Set å­é›†è¿›è¡Œåˆ†æï¼Œé¦–å…ˆçœ‹è¿™äº› Soft label çš„è´¨é‡é«˜ä¸é«˜ï¼Œå³åˆ†åˆ«æµ‹è¯•`$\mathbb{D}_{\text{subset}}$`å’Œ`$\mathbb{D}\setminus \mathbb{D}_{\text{subset}}$`çš„å‡†ç¡®ç‡ã€‚

`\begin{array}{c|cccc} \hline & \textbf{de} & \textbf{es} & \textbf{nl} & \textbf{Avg} \\ \hline \mathbb{D}_{\text{subset}} & 77.87\% & 76.45\% & 84.33\% & 79.55\% \\ \mathbb{D}\setminus \mathbb{D}_{\text{subset}} & 63.83\% & 69.23\% & 66.97\% & 66.68\% \\ \Delta & 14.04\% & 7.22\% & 17.36\% & 12.87\% \\ \hline \end{array}`

å¯ä»¥çœ‹å‡ºåˆ¤åˆ«å™¨ç­›é€‰å‡ºæ¥çš„ data æœ¬èº«å…·æœ‰æ›´å¥½çš„ Soft label è´¨é‡ã€‚
è¿™æ ·ä¹Ÿè¿›ä¸€æ­¥æå‡ä¹‹åçš„ Distillation å­¦ä¹ æ•ˆæœã€‚
é‚£ä¹ˆè¿™æ ·çš„æ€§è´¨æ˜¯å¦ä¿ç•™åˆ° AdvPicker ä¸Šå‘¢ï¼Œå› ä¸ºæˆ‘ä»¬çŸ¥é“ Knowledge Distillation å…¶å®ä¹Ÿæœ‰ä¸€å®šç­›é€‰æ•°æ®è´¨é‡çš„èƒ½åŠ›ã€‚
ç›¸åº”çš„è¿‡ç¨‹åŒæ—¶ä½œç”¨åœ¨ç›®æ ‡è¯­è¨€çš„ Test Set ä¸Šã€‚

`\begin{array}{c|cccccc} \hline & \mathbb{D}^{\text{de}}_{\text{subset}} & \mathbb{D}^{\text{de}}\setminus \mathbb{D}^{\text{de}}_{\text{subset}} & \mathbb{D}^{\text{es}}_{\text{subset}} & \mathbb{D}^{\text{es}}\setminus \mathbb{D}^{\text{es}}_{\text{subset}} & \mathbb{D}^{\text{nl}}_{\text{subset}} & \mathbb{D}^{\text{nl}}\setminus \mathbb{D}^{\text{nl}}_{\text{subset}} \\ \hline \text{mBERT-ft} & 73.65 \% & 70.66 \% & 77.29 \% & 70.39 \% & 81.67 \% & 69.89 \% \\ \text{mBERT-TLADV} & 74.05 \% & 72.49 \% & 78.04 \% & 73.86 \% & 81.83 \% & 77.89 \% \\ \text{UniTrans*} & 74.48\% & 71.71\% & 77.29\% & 73.18\% & 83.15\% & 70.39\% \\ \textbf{AdvPicker} & 75.11\% & 73.76\% & 79.19\% & 75.68 \% & 84.19\% & 79.15 \% \\ \hline \end{array}`

å¯ä»¥çœ‹åˆ°è™½ç„¶ AdvPicker æ²¡æœ‰è§è¿‡è®­ç»ƒé›†ä¸­`$\ell_{\text{score}}(\boldsymbol{x}^{\text{T}})$`æ¯”è¾ƒå°çš„æ•°æ®ï¼Œä½†æ˜¯åœ¨æµ‹è¯•é›†çš„ Other å­é›†ä¸Šä»ç„¶è¶…è¿‡æ‰€æœ‰çš„ Baselinesã€‚
å…¶æ¬¡ï¼Œå¯¹æ¯” UniTrans\*å’Œ mBERT-TLADV, Knowledge Distallation å¯ä»¥è¿›ä¸€æ­¥æå‡æ¨¡å‹åœ¨ä¸¤ä¸ªå­é›†ä¸Šçš„æ•ˆæœï¼Œè€Œä¸” mBERT-TLADV é€šè¿‡å¯¹æŠ—å­¦ä¹ å­¦ä¹ å¾—åˆ°çš„ Language-independent ä½¿å¾—æ¨¡å‹å…·æœ‰æ›´å¥½çš„æ³›åŒ–æ€§ï¼Œåœ¨ Other å­é›†ä¸Šç”šè‡³è¶…è¿‡ UniTrans\*ã€‚

æ­¤å¤–ï¼Œè¿˜è¿›è¡Œäº†ä¸€äº›æ¶ˆèå®éªŒï¼Œè¿›ä¸€æ­¥è¯æ˜äº†å„ä¸ªç»„ä»¶çš„ä½œç”¨ã€‚

`\begin{array}{c|cccc} \hline & \textbf{de} & \textbf{es} & \textbf{nl} & \textbf{Avg} \\ \hline \text{AdvPicker} & 75.02 & 79.00 & 82.90 & 78.97 \\ \hline \text{mBERT-ft} & 72.59 (-2.43) & 75.12 (-3.88) & 80.34 (-2.56) & 76.02 (-2.95) \\ \text{mBERT-TLADV} & 73.89 (-1.13) & 76.92 (-2.08) & 80.62 (-2.28) & 77.14 (-1.83) \\ \text{AdvPicker w/o KD} & 73.98 (-1.04) & 77.91 (-1.09) & 80.55 (-2.35) & 77.48 (-1.49) \\ \text{AdvPicker w All-Data} & 74.02 (-1.00) & 78.72 (-0.28) & 80.69 (-2.21) & 77.81 (-1.16) \\ \hline \end{array}`

## æ€»ç»“å’Œè®¨è®º

æœ¬æ–‡ä» Cross-linugal ä»»åŠ¡åº”è¯¥æ‰‘æ‰ Language-independent ç‰¹å¾çš„è§’åº¦å‡ºå‘ï¼Œè®¾è®¡äº†ä¸€ä¸ªè¯„ä»· Langauge-specific ç¨‹åº¦çš„ä»»åŠ¡ã€‚
å¹¶æ ¹æ®æ­¤ï¼Œè®¾è®¡äº†ä¸€ç§å­—ç¬¦ç²’åº¦çš„å¯¹æŠ—å­¦ä¹ ç­–ç•¥ä»è€Œæå‡æ¨¡å‹å­¦ä¹  Language-independent ç‰¹å¾çš„ç¨‹åº¦ã€‚
å¹¶åˆ©ç”¨å¯¹æŠ—åˆ¤åˆ«å™¨åˆ’åˆ†æ— æ ‡æ³¨ç›®æ ‡è¯­è¨€å­é›†ï¼Œç»§è€Œæ„å»º Soft label å’Œ Knowledge Distillation è¿›ä¸€æ­¥æå‡æ¨¡å‹åœ¨ç›®æ ‡è¯­è¨€ä¸Šçš„æ•ˆæœã€‚
å®éªŒè¯æ˜åœ¨æ— å¤–éƒ¨æ•°æ®çš„å‰æä¸‹ï¼ŒAdvPicker åœ¨ä¸‰ä¸ªè¯­è¨€ä¸Šå‡è¶…è¿‡ä¹‹å‰çš„ SOTAã€‚
å¹¶è®¾è®¡å®éªŒå¯¹åˆ¤åˆ«å™¨äº§ç”Ÿæ•ˆæœçš„åŸå› è¿›è¡Œäº†å…·ä½“åˆ†æã€‚

å®é™…ä¸Šï¼Œè¿™ç§æ–¹å¼å¯ä»¥çœ‹åšä¸ºä¸€ç§å¸¦æƒå€¼æ‰¹å¤„ç†ç‰ˆæœ¬çš„ Self-training æˆ–è€… Co-trainingã€‚
ä½†äº‹å®ä¸Šï¼Œè¿™ç§ Subset Data çš„é€‰æ‹©æ˜¯ä¸ NER æ¨¡å‹å’Œåˆ¤åˆ«å™¨æ¯æ¯ç›¸å…³çš„ï¼Œå®ƒé€‰æ‹©å‡ºæ¥çš„ Data æ˜¯åœ¨å½“å‰ NER æ¨¡å‹ä¸‹ç›¸å¯¹ Language-independentã€‚
