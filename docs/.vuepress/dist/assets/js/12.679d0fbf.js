(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{445:function(t,e,s){"use strict";s.r(e);var a=s(2),i=Object(a.a)({},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"content"},[t._m(0),t._v(" "),t._m(1),t._v(" "),s("p",[t._v("在了解了"),s("router-link",{attrs:{to:"/other/rnn.html"}},[t._v("基本的RNN家族")]),t._v("之后")],1),t._v(" "),t._m(2),t._v(" "),t._m(3),t._v(" "),t._m(4),t._v(" "),t._m(5),t._v(" "),t._m(6),t._v(" "),t._m(7),t._v(" "),t._m(8),t._v(" "),t._m(9),t._v(" "),s("p",[t._v("这个应该很好理解 检索式 只需要 把query+Context encode 到向量 然后计算Similarity，取最高的几个")]),t._v(" "),s("p",[t._v("但生成式 encode计算完之后 还得根据计算值decode成语句 返回给用户")]),t._v(" "),t._m(10),t._v(" "),t._m(11),t._v(" "),t._m(12),t._v(" "),t._m(13),t._v(" "),t._m(14),t._v(" "),t._m(15),t._v(" "),s("p",[t._v("于是就有一堆学者提出一堆模型")]),t._v(" "),s("p",[t._v("常规的做法有利用RNN家族 获取句、文章粒度的信息")]),t._v(" "),s("p",[t._v("然后 就开始论文串讲了")]),t._v(" "),t._m(16),t._v(" "),s("p",[t._v("话说 盘古还没开天 女娲还没补石 后裔还没射日")]),t._v(" "),s("p",[t._v("那个时候 还没有Word2vector 更不用说小学五年级就可以学得TF 对词向量的计算 还都是传统的Hash优化思路")]),t._v(" "),s("p",[t._v("这个时候出现了一个名叫DSSM的模型["),s("code",[t._v("Po-Sen Huang et al. 2013")]),t._v("]  "),s("a",{attrs:{href:"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/cikm2013_DSSM_fullversion.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Learning Deep Structured Semantic Models for Web Search using Clickthrough Data"),s("OutboundLink")],1)]),t._v(" "),t._m(17),t._v(" "),s("p",[t._v("这个模型创新点有")]),t._v(" "),t._m(18),t._v(" "),t._m(19),t._v(" "),s("p",[t._v("随着word2Vec的提出 再加上NN方法在NLP中进一步运用 检索式QA有了不错的发展")]),t._v(" "),s("p",[t._v("但回顾之前的DSSM模型 在计算出句粒度的向量之后就直接使用cosine distance 进行计算Similarity")]),t._v(" "),s("p",[t._v("直观感觉这样算效果不会太好 于是这个时期就有一些学者提出一些改进Similarity计算方法的模型")]),t._v(" "),t._m(20),t._v(" "),s("p",[t._v("就有学者提出由构造对齐矩阵 然后再做池化的方式 计算句粒度之间相似度 的"),s("a",{attrs:{href:"http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11897/12030",target:"_blank",rel:"noopener noreferrer"}},[s("code",[t._v("MV-LSTM")]),t._v("模型["),s("code",[t._v("Shengxian Wan et al. 2015")]),t._v("]"),s("OutboundLink")],1)]),t._v(" "),t._m(21),t._v(" "),s("ol",[s("li",[t._v("计算句子间的两两匹配度存入对齐矩阵 从细粒度描述句子间关系")]),t._v(" "),t._m(22),t._v(" "),s("li",[t._v("Similarity不只直接做cosine计算 根据模型特性动态调整参数"),s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",[s("semantics",[s("mrow",[s("mi",[t._v("s")]),s("mo",[t._v("(")]),s("mi",[t._v("u")]),s("mo",{attrs:{separator:"true"}},[t._v(",")]),s("mi",[t._v("v")]),s("mo",[t._v(")")]),s("mo",[t._v("=")]),s("mi",[t._v("f")]),s("mo",[t._v("(")]),s("msup",[s("mi",[t._v("u")]),s("mi",[t._v("T")])],1),s("msup",[s("mi",[t._v("M")]),s("mrow",[s("mo",[t._v("[")]),s("mn",[t._v("1")]),s("mo",[t._v(":")]),s("mi",[t._v("c")]),s("mo",[t._v("]")])],1)],1),s("mi",[t._v("v")]),s("mo",[t._v("+")]),s("msub",[s("mi",[t._v("W")]),s("mrow",[s("mi",[t._v("u")]),s("mi",[t._v("v")])],1)],1),s("mo",[t._v("[")]),s("mi",[t._v("u")]),s("mo",{attrs:{separator:"true"}},[t._v(";")]),s("mi",[t._v("v")]),s("mo",[t._v("]")]),s("mo",[t._v(")")]),s("mo",[t._v("+")]),s("mi",[t._v("b")]),s("mo",[t._v(")")])],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("s(u,v)=f(u^TM^{[1:c]}v+W_{uv}[u;v])+b)")])],1)],1)],1),t._m(23)])]),t._v(" "),t._m(24)]),t._v(" "),t._m(25),t._v(" "),t._m(26),t._v(" "),s("p",[t._v("这个"),s("a",{attrs:{href:"http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11895/12024",target:"_blank",rel:"noopener noreferrer"}},[t._v("模型["),s("code",[t._v("Liang Pang et al. 2016")]),t._v("]"),s("OutboundLink")],1),t._v("主要是从多个角度 构造对齐矩阵 然后讲多个对齐矩阵 类比图像处理 一起喂入CNN中进行 卷积池化操作 算是"),s("code",[t._v("交互式QA")]),t._v("的开山之作")]),t._v(" "),t._m(27),t._v(" "),s("p",[t._v("文章给出了三种对齐函数的计算方式 1. 存在判断: 该单词是否存在于另一个句子中 2. 点积 3. 余弦相似度")]),t._v(" "),t._m(28),t._v(" "),s("p",[t._v("将多粒度分析出的对齐矩阵 通过多重卷积 进行训练")]),t._v(" "),t._m(29),t._v(" "),t._m(30),t._v(" "),t._m(31),t._v(" "),t._m(32),t._v(" "),s("p",[t._v("在前面学者的基础上 进一步针对多角度句词匹配进行研究 提出"),s("a",{attrs:{href:"https://arxiv.org/pdf/1702.03814",target:"_blank",rel:"noopener noreferrer"}},[t._v("BiMPM模型["),s("code",[t._v("Zhiguo Wang et al. 2017")]),t._v("]"),s("OutboundLink")],1)]),t._v(" "),t._m(33),t._v(" "),s("p",[t._v("文章提出四种匹配方式")]),t._v(" "),t._m(34),t._v(" "),t._m(35),t._v(" "),s("p",[t._v("然后BiMPM还加上了双向处理 不仅考虑从Query 推出Answer 还考虑到Answer 推出 Query")]),t._v(" "),t._m(36),t._v(" "),s("p",[t._v("慢慢的大家发现 仅仅从词的角度 去进行检索式QA不能达到很好的效果")]),t._v(" "),t._m(37),t._v(" "),t._m(38),t._v(" "),s("p",[t._v("说到交互式 必须 提到这篇论文"),s("a",{attrs:{href:"http://www.aclweb.org/anthology/D16-1036",target:"_blank",rel:"noopener noreferrer"}},[t._v("Multi-view Response Selection for Human-Computer Conversation ["),s("code",[t._v("Xiangyang Zhou et al. 2016")]),t._v("]"),s("OutboundLink")],1)]),t._v(" "),s("p",[t._v("虽然它不算完全使用了交互思想的论文 但算作给交互打开了一些思路")]),t._v(" "),t._m(39),t._v(" "),t._m(40),t._v(" "),t._m(41),t._v(" "),t._m(42),t._v(" "),s("p",[t._v("但很显然 这样做 不会有太好的效果")]),t._v(" "),t._m(43),t._v(" "),t._m(44),t._v(" "),s("p",[t._v("然后把两个维度得到的结果相加得到 最终的结果")]),t._v(" "),s("p",[t._v("很显然 直接相加得到的结果 不能准确的反映 多维度之间的关系 但多维度的思路对后面的论文很有帮助")]),t._v(" "),t._m(45),t._v(" "),t._m(46),t._v(" "),s("p",[t._v("然后 就到了大名鼎鼎的"),s("a",{attrs:{href:"https://arxiv.org/pdf/1612.01627",target:"_blank",rel:"noopener noreferrer"}},[t._v("SMN ["),s("code",[t._v("Yu Wu et al. 2017")]),t._v("]"),s("OutboundLink")],1),t._v(" (ym wuyu dalao)")]),t._v(" "),t._m(47),t._v(" "),t._m(48),t._v(" "),t._m(49),t._v(" "),t._m(50),t._v(" "),s("p",[t._v("分别代表词粒度、句粒度")]),t._v(" "),s("p",[t._v("然后经过卷积、池化结合两个粒度的信息")]),t._v(" "),t._m(51),t._v(" "),t._m(52),t._v(" "),s("p",[t._v("这篇文章 还对最后一个GRU进行优化 给出了分别利用1. 最后一个隐藏层结果"),s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",[s("semantics",[s("mrow",[s("mi",[t._v("S")]),s("mi",[t._v("M")]),s("msub",[s("mi",[t._v("N")]),s("mrow",[s("mi",[t._v("l")]),s("mi",[t._v("a")]),s("mi",[t._v("s")]),s("mi",[t._v("t")])],1)],1)],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("SMN_{last}")])],1)],1)],1),t._m(53)]),t._v(" 2. 中间每层的带权和"),s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",[s("semantics",[s("mrow",[s("mi",[t._v("S")]),s("mi",[t._v("M")]),s("msub",[s("mi",[t._v("N")]),s("mrow",[s("mi",[t._v("s")]),s("mi",[t._v("t")]),s("mi",[t._v("a")]),s("mi",[t._v("t")]),s("mi",[t._v("i")]),s("mi",[t._v("c")])],1)],1)],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("SMN_{static}")])],1)],1)],1),t._m(54)]),t._v(" 3. 结合attention的一种表示"),s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",[s("semantics",[s("mrow",[s("mi",[t._v("S")]),s("mi",[t._v("M")]),s("msub",[s("mi",[t._v("N")]),s("mrow",[s("mi",[t._v("d")]),s("mi",[t._v("y")]),s("mi",[t._v("n")]),s("mi",[t._v("a")]),s("mi",[t._v("m")]),s("mi",[t._v("i")]),s("mi",[t._v("c")])],1)],1)],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("SMN_{dynamic}")])],1)],1)],1),t._m(55)]),t._v("进行匹配的结果")]),t._v(" "),s("p",[t._v("得出dynamic 效果最优的结论")]),t._v(" "),t._m(56),t._v(" "),s("p",[t._v("之前 我们 分析过RNNs家族的一些模型")]),t._v(" "),t._m(57),t._v(" "),s("p",[t._v("那么如果把GRU换成RNN的其他模型呢")]),t._v(" "),s("p",[t._v("就有学者提出"),s("a",{attrs:{href:"https://arxiv.org/pdf/1806.09102",target:"_blank",rel:"noopener noreferrer"}},[t._v("DUA模型["),s("code",[t._v("Zhuosheng Zhang et al. 2018")]),t._v("]"),s("OutboundLink")],1),t._v("，把前面M1, M2分别换为GRU, self-attention")]),t._v(" "),t._m(58),t._v(" "),s("p",[t._v("其实 上面这个图画的不好")]),t._v(" "),t._m(59),t._v(" "),t._m(60),t._v(" "),t._m(61),t._v(" "),t._m(62),t._v(" "),t._m(63),t._v(" "),s("p",[t._v("于是有dalao借助 "),s("code",[t._v("transformer")]),t._v(" (其实 也就是 "),s("code",[t._v("self-attentation")]),t._v(" 还记得Google Brain 那篇风骚的 "),s("code",[t._v("Attention is All you need")]),t._v("吧) 提出了"),s("a",{attrs:{href:"http://www.aclweb.org/anthology/P18-1103",target:"_blank",rel:"noopener noreferrer"}},[t._v("Deep Attention Matching ["),s("code",[t._v("Xiangyang Zhou et al. 2018")]),t._v("]"),s("OutboundLink")],1)]),t._v(" "),s("p",[t._v("构造了一些对齐矩阵")]),t._v(" "),t._m(64),t._v(" "),s("p",[t._v("重复2.3H次 就可以得到1+2H层（H为Transformer 层数）对齐矩阵")]),t._v(" "),s("p",[t._v("再把这2H+1维对齐矩阵 喂到CNN中训练")]),t._v(" "),s("p",[t._v("DAM最核心的地方 在于2H层Attention的构造 Paper中给出了具体的解释证明 证明两个Attention 相互作用")]),t._v(" "),t._m(65),t._v(" "),s("p",[t._v("好 基本上 目前常用的模型 介绍完了 也许写完代码会有新的体会 匿了")]),t._v(" "),t._m(66),t._v(" "),t._m(67),t._v(" "),s("ol",[s("li",[s("a",{attrs:{href:"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/cikm2013_DSSM_fullversion.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Learning Deep Structured Semantic Models for Web Search using Clickthrough Data ["),s("code",[t._v("Po-Sen Huang et al. 2013")]),t._v("]"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11897/12030",target:"_blank",rel:"noopener noreferrer"}},[t._v("A Deep Architecture for Semantic Matching with Multiple Positional Sentence Representations["),s("code",[t._v("Shengxian Wan et al. 2015")]),t._v("]"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11895/12024",target:"_blank",rel:"noopener noreferrer"}},[t._v("Text Matching as Image Recognition ["),s("code",[t._v("Liang Pang et al. 2016")]),t._v("]"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://arxiv.org/pdf/1702.03814",target:"_blank",rel:"noopener noreferrer"}},[t._v("Bilateral Multi-Perspective Matching for Natural Language Sentences ["),s("code",[t._v("Zhiguo Wang et al. 2017")]),t._v("]"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"http://www.aclweb.org/anthology/D16-1036",target:"_blank",rel:"noopener noreferrer"}},[t._v("Multi-view Response Selection for Human-Computer Conversation ["),s("code",[t._v("Xiangyang Zhou et al. 2016")]),t._v("]"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://arxiv.org/pdf/1612.01627",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sequential matching network: A new architecture for multi-turn response selection in retrieval-based chatbots ["),s("code",[t._v("Yu Wu et al. 2017")]),t._v("]"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://arxiv.org/pdf/1806.09102",target:"_blank",rel:"noopener noreferrer"}},[t._v("Modeling multi-turn conversation with deep utterance aggregation ["),s("code",[t._v("Zhuosheng Zhang et al. 2018")]),t._v("]"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"http://www.aclweb.org/anthology/P18-1103",target:"_blank",rel:"noopener noreferrer"}},[t._v("Multi-Turn Response Selection for Chatbots with Deep Attention Matching Network ["),s("code",[t._v("Xiangyang Zhou et al. 2018")]),t._v("]"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/44539292",target:"_blank",rel:"noopener noreferrer"}},[t._v("小哥哥，检索式chatbot了解一下？"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://blog.csdn.net/xiayto/article/details/81247461",target:"_blank",rel:"noopener noreferrer"}},[t._v("深度文本匹配发展总结"),s("OutboundLink")],1)])]),t._v(" "),s("link",{attrs:{rel:"stylesheet",href:"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"}}),t._v(" "),s("link",{attrs:{rel:"stylesheet",href:"https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css"}})])},[function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("拖了一个多星期了 都快拖到Final Presentation DDL了 我这个"),e("code",[this._v("懒癌晚期")]),this._v("都看不下去了")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("好 究竟是道德的沦丧还是人性的扭曲？欢迎来到这一期的"),e("code",[this._v("「奇葩说之中华田园犬大解密」")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("我们把步子迈得大一点 直接对准目前"),e("code",[this._v("检索式")]),this._v(" "),e("code",[this._v("chatbots")]),this._v("研究前沿")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("首先 QA系统分为"),e("code",[this._v("任务型")]),this._v("，"),e("code",[this._v("非任务型")]),this._v("两大类")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("code",[this._v("任务型")]),this._v("就是像Siri这种，需要识别用户派遣的任务，然后完成相应的任务")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("而"),e("code",[this._v("非任务")]),this._v("则是主要是闲聊机器人，购物客服机器人")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("code",[this._v("非任务")]),this._v("按Answer的生成方式 又可以分为 "),e("code",[this._v("检索式")]),this._v(" "),e("code",[this._v("生成式")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("目前工业上落地的(效果好的)就是"),e("code",[this._v("检索式")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("所以我们为了学术 "),e("s",[this._v("(找工作)")]),this._v(" 来研究"),e("code",[this._v("检索式")]),this._v("对话Chatbots")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("code",[this._v("检索式QA")]),this._v(" 和 "),e("code",[this._v("生产式QA")]),this._v(" 最大的区别 就是 检索式 只需要做"),e("code",[this._v("encode")]),this._v(" 而生成式不仅仅要encode 还要"),e("code",[this._v("decode")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("这就是他们最大的区别 当然 我们这里讨论的是"),e("code",[this._v("检索式")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"base-mind"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#base-mind","aria-hidden":"true"}},[this._v("#")]),this._v(" Base mind")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("检索式对话 顾名思义 就是从一堆语料库中 通过"),e("code",[this._v("检索")]),this._v(" 来"),e("code",[this._v("匹配")]),this._v("到相近的对话 从而输出答案")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("注意 这里有两个关键词 一个是"),e("code",[this._v("检索")]),this._v(" 另外一个是"),e("code",[this._v("匹配")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("code",[this._v("检索")]),this._v("就是 检查索引 所以 检索的关键就是把词变成词向量 预处理成Index")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("code",[this._v("匹配")]),this._v("就是 根据词向量 计算出一个匹配值 最简单就是计算Cosine Distance 当然这样效果很一般")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"上古时代"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#上古时代","aria-hidden":"true"}},[this._v("#")]),this._v(" 上古时代")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:"https://cdn.nlark.com/yuque/0/2018/png/104214/1542345404535-fde510e8-39e7-40b8-a620-b0eeb4b9fba0.png",alt:"图片.png | center | 556x500"}})])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("ol",[s("li",[t._v("利用"),s("code",[t._v("wordHash")]),t._v("代替传统词袋模型 从而达到降维效果\n"),s("ul",[s("li",[s("code",[t._v("word Hash")]),t._v(" 就是用把词前后加上"),s("code",[t._v("#")]),t._v("，然后每n个词做一个切割，比如说"),s("code",[t._v("good")]),t._v("->{"),s("code",[t._v("#go")]),t._v(", "),s("code",[t._v("goo")]),t._v(", "),s("code",[t._v("ood")]),t._v(", "),s("code",[t._v("od#")]),t._v("}")]),t._v(" "),s("li",[t._v("每个切割分量作为一维向量")]),t._v(" "),s("li",[t._v("因为英文中单词数量级远大于n个字母组合的数量级")]),t._v(" "),s("li",[t._v("且这种方案的Hash碰撞率较小 3字母表示仅为"),s("code",[t._v("0.0044％")])]),t._v(" "),s("li",[t._v("WordHash可以看做是"),s("code",[t._v("Word2Vector")]),t._v("早期的方案")]),t._v(" "),s("li",[t._v("其基本思想每个词之间并非完全正交 然后应该没有那么多独立的维度 所以就可以压缩词向量大小")])])]),t._v(" "),s("li",[t._v("利用"),s("code",[t._v("全神经网络")]),t._v("对句子进行处理得到相对应的句粒度向量\n"),s("ul",[s("li",[t._v("文章利用三个隐藏层进行训练，第一个隐藏层为WordHash层有30K个节点，第二三层各有300个节点，输出层有128个节点，并使用随机梯度下降SGN训练")])])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"启蒙运动"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#启蒙运动","aria-hidden":"true"}},[this._v("#")]),this._v(" 启蒙运动")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h3",{attrs:{id:"mv-lstm"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mv-lstm","aria-hidden":"true"}},[this._v("#")]),this._v(" "),e("code",[this._v("MV-LSTM")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:"https://cdn.nlark.com/yuque/0/2018/png/104214/1542351846290-e23d67f2-5c47-4284-9e01-612b9a03ac7d.png",alt:"图片.png | center | 556x500"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("li",[this._v("利用"),e("code",[this._v("双向LSTM")]),this._v("模型 减少因为RNN时序遍历的特性 导致模型结果更偏向于最后几个单词的现象")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"strut",staticStyle:{height:"0.8879999999999999em"}}),s("span",{staticClass:"strut bottom",staticStyle:{height:"1.138em","vertical-align":"-0.25em"}}),s("span",{staticClass:"base textstyle uncramped"},[s("span",{staticClass:"mord mathit"},[t._v("s")]),s("span",{staticClass:"mopen"},[t._v("(")]),s("span",{staticClass:"mord mathit"},[t._v("u")]),s("span",{staticClass:"mpunct"},[t._v(",")]),s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.03588em"}},[t._v("v")]),s("span",{staticClass:"mclose"},[t._v(")")]),s("span",{staticClass:"mrel"},[t._v("=")]),s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10764em"}},[t._v("f")]),s("span",{staticClass:"mopen"},[t._v("(")]),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathit"},[t._v("u")]),s("span",{staticClass:"vlist"},[s("span",{staticStyle:{top:"-0.363em","margin-right":"0.05em"}},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),s("span",{staticClass:"reset-textstyle scriptstyle uncramped"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.13889em"}},[t._v("T")])])]),s("span",{staticClass:"baseline-fix"},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10903em"}},[t._v("M")]),s("span",{staticClass:"vlist"},[s("span",{staticStyle:{top:"-0.363em","margin-right":"0.05em"}},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),s("span",{staticClass:"reset-textstyle scriptstyle uncramped"},[s("span",{staticClass:"mord scriptstyle uncramped"},[s("span",{staticClass:"mopen"},[t._v("[")]),s("span",{staticClass:"mord mathrm"},[t._v("1")]),s("span",{staticClass:"mrel"},[t._v(":")]),s("span",{staticClass:"mord mathit"},[t._v("c")]),s("span",{staticClass:"mclose"},[t._v("]")])])])]),s("span",{staticClass:"baseline-fix"},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.03588em"}},[t._v("v")]),s("span",{staticClass:"mbin"},[t._v("+")]),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.13889em"}},[t._v("W")]),s("span",{staticClass:"vlist"},[s("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.13889em"}},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),s("span",{staticClass:"reset-textstyle scriptstyle cramped"},[s("span",{staticClass:"mord scriptstyle cramped"},[s("span",{staticClass:"mord mathit"},[t._v("u")]),s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.03588em"}},[t._v("v")])])])]),s("span",{staticClass:"baseline-fix"},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),s("span",{staticClass:"mopen"},[t._v("[")]),s("span",{staticClass:"mord mathit"},[t._v("u")]),s("span",{staticClass:"mpunct"},[t._v(";")]),s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.03588em"}},[t._v("v")]),s("span",{staticClass:"mclose"},[t._v("]")]),s("span",{staticClass:"mclose"},[t._v(")")]),s("span",{staticClass:"mbin"},[t._v("+")]),s("span",{staticClass:"mord mathit"},[t._v("b")]),s("span",{staticClass:"mclose"},[t._v(")")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("li",[this._v("处理最后一步使用多层感知机"),e("code",[this._v("MLP")]),this._v("对得到的结果进行压缩和分类 因为效果较好 这个做法在之后的论文中被广泛采用")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h3",{attrs:{id:"mm"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mm","aria-hidden":"true"}},[this._v("#")]),this._v(" "),e("code",[this._v("MM")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("blockquote",[e("p",[this._v("MM = Matching Matrix")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:"https://cdn.nlark.com/yuque/0/2018/png/104214/1542353262588-eed0a08d-2a37-41d6-8cbb-b03054846889.png",alt:"图片.png | center | 556x500"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:"https://cdn.nlark.com/yuque/0/2018/png/104214/1542353290710-66dc00ee-c423-4a23-8c0e-3804b688e66a.png",alt:"图片.png | center | 556x500"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:"https://cdn.nlark.com/yuque/0/2018/png/104214/1542353318367-9f27cfa9-d6ae-4f94-b502-bb857b3742bf.png",alt:"图片.png | center | 556x500"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("然后这种多粒度计算词、句之间关系的做法 之后发展成"),e("code",[this._v("交互式QA")]),this._v(" 现广泛应用于检索式QA模型中")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h3",{attrs:{id:"bimpm"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#bimpm","aria-hidden":"true"}},[this._v("#")]),this._v(" "),e("code",[this._v("BiMPM")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("blockquote",[e("p",[this._v("BiMPM = Bilateral Multi-Perspective Matching")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:"https://cdn.nlark.com/yuque/0/2018/png/104214/1542354627538-9500438e-7e1b-4f92-872e-5275e76b9df0.png",alt:"图片.png | center | 556x500"}})])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("ol",[s("li",[s("code",[t._v("Full Matching")]),t._v(": 每个单词 与 需要匹配的句子的最后一个"),s("code",[t._v("隐藏层")]),t._v("输出向量进行Cosine计算")]),t._v(" "),s("li",[s("code",[t._v("MaxPooling Matching")]),t._v(": 每个单词 与 需要匹配的句子的"),s("code",[t._v("每一个单词")]),t._v("进行Cosine计算 取"),s("code",[t._v("Maximum")])]),t._v(" "),s("li",[s("code",[t._v("Attentive Matching")]),t._v(": 每个单词 与 需要匹配的句子的每一个单词行Cosine计算 然后用Softmax归一化 "),s("code",[t._v("作为attention权重")]),t._v(" 然后再"),s("code",[t._v("加权求和")]),t._v(" 得到的结果再做一次Cosine")]),t._v(" "),s("li",[s("code",[t._v("Max Attentive Matching")]),t._v(": 每个单词 与 需要匹配的句子的每一个单词行Cosine计算 然后用Softmax归一化 作为attention权重 然后再"),s("code",[t._v("取最大值")]),t._v(" 得到的结果再做一次Cosine")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:"https://cdn.nlark.com/yuque/0/2018/png/104214/1542355478297-e5ad297c-bd25-4528-a833-be0ab27284cd.png",alt:"图片.png | center | 556x500"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"工业革命"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#工业革命","aria-hidden":"true"}},[this._v("#")]),this._v(" 工业革命")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("尤其是在多轮对话中效果并不好 于是能反映多角度关系且特别"),e("code",[this._v("Work")]),this._v("(这个很关键)的交互式就越来越流行")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h3",{attrs:{id:"multi-view-model"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#multi-view-model","aria-hidden":"true"}},[this._v("#")]),this._v(" "),e("code",[this._v("Multi-view model")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("然后 看完这篇Paper "),e("code",[this._v("LongLong Ago")]),this._v(" 才发现 这篇论文是我老师写的 "),e("s",[this._v("（虽然他的名字 藏在最后）")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:"https://cdn.nlark.com/yuque/0/2018/png/104214/1542356643949-b78cc707-3d22-4990-9643-6cc5ce4e7854.png",alt:"图片.png | center | 556x500"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("我们在研究多轮对话的时候 很简单的一个想法就是把多轮用一些标识符(比如说"),e("code",[this._v("_SOS_")]),this._v(")拼接成一句单句 然后这个单句就可以像上面一样计算对齐矩阵")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:"https://cdn.nlark.com/yuque/0/2018/png/104214/1542356794106-424b4565-3fef-49d6-af19-8411d2afb194.png",alt:"图片.png | center | 556x500"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("于是这篇Paper 提出通过多角度 ("),e("code",[this._v("Word Level")]),this._v(", "),e("code",[this._v("Utterance Level")]),this._v(")")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("code",[this._v("Utterance")]),this._v("是指利用CNN 进行卷积池化 得到Utterance Level的embedding squence 再经过一次Gated RNN (LSTM or GRU)过滤噪声")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h3",{attrs:{id:"smn"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#smn","aria-hidden":"true"}},[this._v("#")]),this._v(" "),e("code",[this._v("SMN")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("blockquote",[e("p",[this._v("SMN = Sequential Matching Network")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("code",[this._v("SMN")]),this._v(" 把多粒度、基于交互的思想运用在多轮对话中")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:"https://cdn.nlark.com/yuque/0/2018/png/104214/1542358541211-bf819107-ce5f-4085-868c-c5e675aad8bd.png",alt:"图片.png | center | 556x500"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("和前面的"),e("code",[this._v("MM")]),this._v("等模型一样 "),e("code",[this._v("SMN")]),this._v("采用了多粒度分析")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("ul",[s("li",[t._v("一个对齐矩阵M1 是直接"),s("code",[t._v("Word Embedding")]),t._v(" 得到的 对应的就是"),s("code",[t._v("Word Pairs")])]),t._v(" "),s("li",[t._v("另外一个矩阵M2 是通过"),s("code",[t._v("GRU")]),t._v("计算得到的 对应的是"),s("code",[t._v("Segment Pairs")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("然后再过一层"),e("code",[this._v("GRU")]),this._v(" 过滤噪声 "),e("code",[this._v("GRU")]),this._v("得到的向量进行Match就可以获得匹配Score")])},function(){var t=this.$createElement,e=this._self._c||t;return e("blockquote",[e("p",[this._v("这种多粒度的做法 保证了即使CNN很浅，也能抽取出比较high-level的特征，得到高质量的utterance embedding[9]")])])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"strut",staticStyle:{height:"0.68333em"}}),s("span",{staticClass:"strut bottom",staticStyle:{height:"0.83333em","vertical-align":"-0.15em"}}),s("span",{staticClass:"base textstyle uncramped"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.05764em"}},[t._v("S")]),s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10903em"}},[t._v("M")]),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10903em"}},[t._v("N")]),s("span",{staticClass:"vlist"},[s("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.10903em"}},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),s("span",{staticClass:"reset-textstyle scriptstyle cramped"},[s("span",{staticClass:"mord scriptstyle cramped"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")]),s("span",{staticClass:"mord mathit"},[t._v("a")]),s("span",{staticClass:"mord mathit"},[t._v("s")]),s("span",{staticClass:"mord mathit"},[t._v("t")])])])]),s("span",{staticClass:"baseline-fix"},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])])])])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"strut",staticStyle:{height:"0.68333em"}}),s("span",{staticClass:"strut bottom",staticStyle:{height:"0.83333em","vertical-align":"-0.15em"}}),s("span",{staticClass:"base textstyle uncramped"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.05764em"}},[t._v("S")]),s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10903em"}},[t._v("M")]),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10903em"}},[t._v("N")]),s("span",{staticClass:"vlist"},[s("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.10903em"}},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),s("span",{staticClass:"reset-textstyle scriptstyle cramped"},[s("span",{staticClass:"mord scriptstyle cramped"},[s("span",{staticClass:"mord mathit"},[t._v("s")]),s("span",{staticClass:"mord mathit"},[t._v("t")]),s("span",{staticClass:"mord mathit"},[t._v("a")]),s("span",{staticClass:"mord mathit"},[t._v("t")]),s("span",{staticClass:"mord mathit"},[t._v("i")]),s("span",{staticClass:"mord mathit"},[t._v("c")])])])]),s("span",{staticClass:"baseline-fix"},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])])])])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"strut",staticStyle:{height:"0.68333em"}}),s("span",{staticClass:"strut bottom",staticStyle:{height:"0.969438em","vertical-align":"-0.286108em"}}),s("span",{staticClass:"base textstyle uncramped"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.05764em"}},[t._v("S")]),s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10903em"}},[t._v("M")]),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10903em"}},[t._v("N")]),s("span",{staticClass:"vlist"},[s("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.10903em"}},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),s("span",{staticClass:"reset-textstyle scriptstyle cramped"},[s("span",{staticClass:"mord scriptstyle cramped"},[s("span",{staticClass:"mord mathit"},[t._v("d")]),s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.03588em"}},[t._v("y")]),s("span",{staticClass:"mord mathit"},[t._v("n")]),s("span",{staticClass:"mord mathit"},[t._v("a")]),s("span",{staticClass:"mord mathit"},[t._v("m")]),s("span",{staticClass:"mord mathit"},[t._v("i")]),s("span",{staticClass:"mord mathit"},[t._v("c")])])])]),s("span",{staticClass:"baseline-fix"},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h3",{attrs:{id:"dua"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#dua","aria-hidden":"true"}},[this._v("#")]),this._v(" "),e("code",[this._v("DUA")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("在刚才的"),e("code",[this._v("SMN")]),this._v("模型中 利用了GRU获得时序信息")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:"https://cdn.nlark.com/yuque/0/2018/png/104214/1542361352470-4c4da4a9-2c4a-4db9-a234-decb9baf0582.png",alt:"图片.png | center | 556x500"}})])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("ul",[s("li",[t._v("一个对齐矩阵M1 是通过"),s("code",[t._v("GRU")]),t._v("计算得到的 对应的是"),s("code",[t._v("Segment Pairs")])]),t._v(" "),s("li",[t._v("另外一个矩阵M2 是先"),s("code",[t._v("self-attentation")]),t._v(" 然后和embedding的结果拼起来 再过一次"),s("code",[t._v("GRU")]),t._v(" "),s("ul",[s("li",[t._v("这里的"),s("code",[t._v("slef-attentation")]),t._v(" 没有使用position 所以没有带时序信息 于是用"),s("code",[t._v("GRU")]),t._v(" 捞一下有关时间的信息")])])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("之后的就和"),e("code",[this._v("SMN")]),this._v("基本一致 实际效果比"),e("code",[this._v("SMN")]),this._v("更好一点")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h3",{attrs:{id:"dam"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#dam","aria-hidden":"true"}},[this._v("#")]),this._v(" "),e("code",[this._v("DAM")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:"https://cdn.nlark.com/yuque/0/2018/png/104214/1542361915086-a0f3f760-c899-45fa-b04e-aac2ab94ec54.png",alt:"图片.png | center | 556x500"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("前面的"),e("code",[this._v("SMN")]),this._v("给了两层对齐矩阵 那么为啥选两层 不选三层 四层 100层 8848层呢")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("ol",[s("li",[t._v("原始"),s("code",[t._v("word embedding")]),t._v(" 矩阵")]),t._v(" "),s("li",[t._v("第一层"),s("code",[t._v("Attention")]),t._v(": 多轮Contetxt和Response 每个词")]),t._v(" "),s("li",[t._v("第二层"),s("code",[t._v("Attention")]),t._v(": 第一轮结果和新的Response")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("目前"),e("code",[this._v("DAM")]),this._v("模型可以获得不错的结果")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("strong",[this._v("---未完待续 期待下一个篇章---")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"reference"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#reference","aria-hidden":"true"}},[this._v("#")]),this._v(" Reference")])}],!1,null,null,null);i.options.__file="chatbot.md";e.default=i.exports}}]);