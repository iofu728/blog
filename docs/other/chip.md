---
title: 底层码农眼中的芯片
date: 2018-12-05 18:24:01
tags: [chip]
description: chip
---

> 这周四个展示 终于要熬到最后一个了 good luck

今天来讨论这个问题 显得有些`应景` 和 `无力` 刚说不再贸易战 还搞菊厂 这只能说Trump是一个鳝变的男人👱

`什么是芯片？`

当中兴事件发生的时候 铺天盖地的新闻在报道『中国芯片』

看到这些新闻的时候 我一蒙 我不知道这里的芯片指的是什么

也许它什么都指 这可能是才最恐怖的

以电脑为例 基本上所有器件都可以称为芯片

> * 计算芯片: CPU GPU TPU NPU FRGA
> * 存储芯片: DRAM SDRAM ROM FLASH
> * 通信芯片: 蓝牙 WIFI NB-IOT 宽带ADSL
> * 传感器: 陀螺仪 MEMS 指纹芯片麦克 摄像
> * 接口芯片: USB 网卡 HDMI DP
> * 电源芯片: 反正大家不认识就不列了

但很明显各个部分的重要程度不一样

![图片.png | center | 556x500](https://cdn.nlark.com/yuque/0/2018/png/104214/1544026738576-83e962a7-6d8d-41a0-822c-f50a916a3249.png "")

CPU速度很快 I/O速度超慢

为了连接这二者 就出现了中间这条总线

CPU负责高速运算 然后把数据通过前端总线 经过北桥(内存管理集线器) 传给内存 和 GPU

这个时候速度已经降了一级

然后再通过网络总线 继续往下传 由南桥(也就是I/O控制集线器) 传给各个外部 端口

比如说什么SATA硬盘，USB，网卡，视频，音频，CMOS

最后再经过LPC总线(就是很慢的总线) 与ROM中的BIOS、更慢一点的I/O连接

比如说串行端口 并行端口 键盘 鼠标啥的

到这里 整个PC机的芯片就串在一起了 作为一名合格的`装系统工程师` 应该熟练掌握😂

## `CPU`

> `核心` + `指令集架构/CPU架构/处理器架构` + `微架构` = `CPU` - `OS`

核心指的就是CPU的硬件 包括ALU运算器 等等的

指令 就是 一个约定好的暗号

比如说 你对狗狗喊‘蹲下’ 它做出相应的反应 这就是一个指令完成的过程

当然如果你这样对🐶说 可能不一定有用 这就是一个不成功的指令

微架构呢 就是管理硬件的一些操作

指令集 大部分 都是不开源的 只有授权了 才能拿到使用权

可以想到 指令集作为一种约定 用的人多了 这个指令集才值钱

因为更换成本较大 再加上一些垄断的原因 现在世界上只有少数几种通用的指令集

相对而言 在微架构方面 就有很多创新空间 所以现在包括 三星 苹果 小米 等公司 都是在这个领域进行自己的设计

![图片.png | center | 556x500](https://cdn.nlark.com/yuque/0/2018/png/104214/1544104814933-dcd36eb0-da60-4745-8da1-f5d54184fa3c.png "")

### 指令集架构

指令集分为复杂指令集RISC和精简指令集CISC两种

两者最大的差别就是RISC支持变长度的指令 CISC只支持定长度的指令

这有什么区别呢 我们看一个例子

> RISC: Thecatsatandatehishat
> CISC: The cat sat and ate his hat.

复杂指令集相当于读上面那句话 精简指令集呢相当于读下面这句话 很明显下面更容易获取信息

但定长也导致了拓展性低 各有优缺点

CISC目前常用的商业指令集有`ARM`,`Power`,`MIPS`

其中 ARM 独占移动端 市场 主要是因为Intel在起步阶段不够重视移动端

Power是IBM开发的一个指令集 看用它的产品有`XBOX 360`,`PS3`, `Wii Ui`这个是Switch上一代产品 总结一下 这些都是上一代掌机

现在的掌机为了追求GPU效果 都换成了ARM 真香

MIPS是一个开源指令集 被中科院购买下来 后来成为龙芯公司 龙芯也是大陆第一个自主研制出能在Win上跑的芯片的公司（虽然只是WIn CN）

而复杂指令集呢 现在只有X86比较常用 X86是Intel开发与AMD互相授权的一个指令集 基本上垄断了PC机

一个原因是因为Intel 微架构确实优化的叼 制作工艺也屌 在Intel这制程都不是事 落后一代也能吊打你 10nm和台积电7nm差不多 真的恐怖

还有一个很重要的原因 就是Win只支持X86(现在也支持ARM了 但 那还是Win吗)

所以如果你想开发能给Win用的CPU你就必须获得X86授权

目前大陆只有两家公司获得X86的授权 一家是兆芯 一家是海光

兆芯的授权来自台湾公司VIA 而VIA的X86授权来自美国反垄断协会判给VIA的使用权 相对来说授权较为不稳定 而且技术支持较为薄弱

海光是AMD在中国的合资公司 AMD技术底蕴更强 合作意愿也更大 但起步晚

我的观点 CPU指令集很难创新 也没必要创新 有研究表明指令集与能耗性能无明显关系

最重要的是已经形式相应的生态研制成本已经很大了 更换成本更大

### 微架构

微架构是各大公司创新点

目前微架构有以下几种常见的方向

> * 流水线化
> * 多核、多线程
> * SIMD 向量
> * 存储系统分层结构

![图片.png | center | 556x500](https://cdn.nlark.com/yuque/0/2018/gif/104214/1544030318796-c90772e8-e81e-4c94-9243-ea17ce66cf09.gif "")

流水线 就相当于时间上的并行 每个核心反复做相同的工作 由不同核心共同完成一个任务

多线程 就相当于 空间上的并行

SIMD就是单指令多数据 一次导一组数据 增加效率

前两天刚好在研究一个在内存数据库中利用SIMD构建DBMS的问题

可以看出微架构 是一个体系结构问题

在这之中有很多工作可以做

## SOC

SOC是手机上的芯片的集合体

里面有CPU GPU DSP（用于多媒体解码）有些还有NPU 通讯芯片蓝牙 LCD 摄像头 GPS等等

![图片.png | center | 556x500](https://cdn.nlark.com/yuque/0/2018/png/104214/1544031389853-70f4b62b-5d53-4806-8fcf-eefd5df9d7c9.png "")

按功能可以分为AP BP 其他

BP主要功能是通信 包括基带和射频 基带主要负责通信信号的处理 射频主要负责信号的收发

AP则可以看做PC机 负责系统的处理

在AP BP中间都有相应的CPU DSP 电源等等

ARM 把CPU核心卖给各大厂商比如说高通 三星 苹果

ARM不仅做硬件贩卖商 也自己生产设计了自己的微架构 提供给各大IP提供商

这其中就有一个很著名的例子 就是2015年的骁龙810

当时高通第一次做8核心的SOC 没啥经验 用的公版芯片 就是ARN卖芯片送的微架构

这就导致了著名的暖手宝芯片 都说有了骁龙810 妈妈再也不怕我冻着了

当然骁龙810用的是20nm工艺也是一部分原因

## GPU

> GPU: graphics processing unit

虽然叫这个名字 但GPU还是一个通用的计算芯片 不仅可以用于图像加速 还可以用于深度学习中

CPU是基于冯诺依曼体系 顺序执行

GPU呢则是讲究并行化处理 GPU利用其远大于CPU的核心数达到并行的效果

CPU中因为通用性 存在很多缓存存储机制

一个直观的感受 一个GPU中运算单元的个数 VS CPU中运算单元大概能达到 这样的一个比例

![图片.png | center | 556x500](https://cdn.nlark.com/yuque/0/2018/png/104214/1544031645933-e337dcf0-c39a-4f4f-9b27-b9b75b6fb6e1.png "")

拿我自己的感受 Mac没有N卡 每次跑模型 都是别人几倍的时间 留下了没有GPU的眼泪😢

右下角是NVIDIA刚刚发布的一款适合深度学习的GPU 拥有4k多个核心 但是价格 看看就好了 这么大的煤气灶 居然要2.5k刀 穷

## TPU

TPU就不是通用的计算芯片 是一种AISC特定用途的芯片 由google设计专门对TensorFlow进行优化

举一个例子 在10月份 Google发布了一个基础TensorFlow的模型Bert

这个模型一出 就轰动NLP届

有人称之为NLP的春天 在它发布一个多月时间内

屠杀了各大NLP任务排行榜 比如说这个由Stanford发布的阅读理解领域权威数据集

![图片.png | center | 556x500](https://cdn.nlark.com/yuque/0/2018/png/104214/1544104977958-c9f04811-f5fc-46db-b945-2c22ea1994b7.png "")

可以看到前7名全是用Bert的 足足把原有的水平提高7.8个百分点 十分接近人类表现了

但这个武器威力无比 但代价很大 大在哪 它用了几千层Attention 计算量非常大

论文中Google Brain的老哥用了16块TPU跑了4天 换算成钱💰 就是12k刀跑一次 留下了没有TPU的眼泪

事实上 TPU Google也不卖 只能提高云服务购买

所以有人说 Bert相当于核武器 虽然威力无比 但代价也很大

`Money is all you need`

然后这是TPU的设计架构

![图片.png | center | 556x500](https://cdn.nlark.com/yuque/0/2018/png/104214/1544105141639-fc4d5248-8a1d-4876-86e1-d1eb34d2f5c0.png "")

可以看出TPU相较于GPU 缓冲区更小 计算核心更多 而且采用SIMD架构 专门对大I/O进行优化

## AISC

近些年来 AI持续走热 各大公司 都推出了自己的AI芯片

但要明白这些芯片 并不是像CPU GPU那样通用的芯片 只是针对专门任务进行优化的特殊功能芯片 称之为AISC

我们知道在机器学习中 分为两个步骤 先是用 数据训练出一个模型 然后在用这个模型 预测出结果

在训练中一般参数需要是浮点数 对计算性能要求就比较高

而预测过程中不再需要高精度浮点数 故有些人用8位长度来进行优化 推出了针对推测阶段的 推测芯片

比如说寒武纪1A

虽然我个人觉得在手机上用的NPU都是垃圾

手机上能耗的限制 基本不能进行训练 如果要预测 那个模型的大小大概是5MB左右 才能跑起来

现在的机器学习训练出来的模型基本上都是几个GB 于是目前在手机上的NPU效果不会太好

![图片.png | center | 556x500](https://cdn.nlark.com/yuque/0/2018/png/104214/1544105250834-9d9341dc-d921-4d96-9e3a-2782c11c92a2.png "")

## Clound Chip

可以看出越来越多的云厂商推出自己的AI芯片

尤其是Google推出TPU效果挺不错的

首先 什么是Cloud

cloud 就是租用部署在云端的服务器

![图片.png | center | 556x500](https://cdn.nlark.com/yuque/0/2018/png/104214/1544105360176-f19a1c30-0f09-4ca2-8cb6-85be27a01cff.png "")

为啥要租用而不是购买呢 主要原因就是弹性扩容 以便资源最大利用

比如说微博 在一些明星有大瓜的时候 就会扩容 微博号称可以支持并发出轨

还好在上周的吃瓜日中 终于抗住了 压力

云服务厂商 比如说华为 AWS 微软 都推出了自己的AI芯片

这种云服务厂商的芯片 具有独特性 可以捆绑用户购买其服务器

像这种机器学习机器购买 费用就会比较高

![图片.png | center | 556x500](https://cdn.nlark.com/yuque/0/2018/png/104214/1544105446799-9af5dab4-6e11-44c6-9fa4-0c2b52d9efda.png "")
