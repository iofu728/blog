---
title: è¯•è°ˆè¯­è¨€æ¨¡å‹ä¸­æ— ç›‘ç£éç»“æ„åŒ–çŸ¥è¯†èå…¥
date: 2020-04-06 19:31:13
tags: [NLP, LM]
description: Unsupervised unstructured Knowledge infusion in LMs
---

[ğŸ”« Reading Group çš„ pdf ç‰ˆæœ¬](https://www.yuque.com/preview/yuque/0/2020/pdf/104214/1586187444506-2c27d9ef-d29a-4b2f-9581-479901113e1e.pdf)

> 1. ç»“æ„åŒ–/çº¯æ–‡æœ¬

ä¹‹å‰çš„ä¸€ç³»åˆ—å°†çŸ¥è¯†èå…¥ BERT çš„å·¥ä½œå¤§å¤šåŸºäº entity ä¸‰å…ƒç»„è¿™ç§ç»“æ„åŒ–æ•°æ®.

è¿™å°±è¦æ±‚æœ‰å¤§é‡ä¸”é«˜è´¨é‡çš„äººå·¥æ ‡æ³¨(å½“ç„¶æˆ‘ä»¬æœ‰ HowNet, WordNet, WikiData), äººå·¥æ ‡æ³¨å¿…ç„¶å‡ºç°å¤§é‡å™ªå£°, ç»“æ„åŒ–æ•°æ®æ›´æ–°å‘¨æœŸæ™®éæ›´é•¿.

MLM çš„æ— ç›‘ç£æ˜¯å¦æ˜¯æ— ç›‘ç£çš„æé™(å½“ç„¶ ERNIE 2.0 é‚£ç§åè¯­æ³•çš„ä»»åŠ¡ä¹Ÿå¯ä»¥ç®—), èƒ½å¦æœ‰ä¸€ç§æ— ç›‘ç£æˆ–è€…å¼±ç›‘ç£çš„ä»»åŠ¡/æ¨¡å¼ å¢å¼ºåŸå…ˆçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¸­çš„çŸ¥è¯†ä¿¡æ¯.

> 2. LMs are KBsï¼Ÿ

[EMNLP 2019 çš„è¿™ç¯‡æ–‡ç«  Language Models as Knowledge Bases?](https://arxiv.org/abs/1909.01066) è®¾è®¡äº† cloze style çš„ Probing å®éªŒ(å¤§å¤šæ˜¯ Commensense çš„é—®ç­”ä»»åŠ¡)æ¥è¯æ˜è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†æ€§.

è™½ç„¶ç°åœ¨çœ‹èµ·æ¥è¯­è¨€æ¨¡å‹å­¦åˆ°çš„æ›´å¤šè¿˜æ˜¯å…±ç°å…³ç³», å¯¹äºä½é¢‘è¯æ•ˆæœæ²¡æœ‰é‚£ä¹ˆå¥½, ä½†æ‰€è•´å«çš„çŸ¥è¯†ä¿¡æ¯å‡ ä¹å’Œ KBs ç±»çš„æ–¹æ³•ç›¸è¿‘.

é™¤å» RoBERTa è¿™ä¸ªå¼‚ç±», ä¹‹å‰çš„å·¥ä½œæ˜¾ç¤ºä¸ fine-tune æ—¶è¿œä½äºå…¶ä»– LMs, fine-tune äº†åˆè¿œé«˜äºå…¶ä»–.

æƒ³åŠæ³•å¢åŠ  LMs çš„çŸ¥è¯†èƒ½åŠ›è¿˜æ˜¯å¾ˆæœ‰é“ç†çš„.

> 3. è„šæ³¨/å¼•ç”¨

åœ¨æ—¥å¸¸ä¹¦å†™ä¸­, å…¶å®æˆ‘ä»¬ä¼šå¤§é‡ä½¿ç”¨è„šæ³¨/å¼•ç”¨æ¥è§£é‡ŠçœŸå®çš„å«ä¹‰, è¾…åŠ©è¯»è€…ç†è§£.

å¯¹äºè¯­è¨€æ¨¡å‹æ¥è¯´, è¿™éƒ¨åˆ†ä¿¡æ¯æ˜¯ç¼ºå¤±çš„.

åŸºäºä»¥ä¸Šå‡ ç‚¹, è¿™ç¯‡æ–‡ç« æµ…æ˜¾çš„ä»‹ç»ä¸€ä¸‹ç›®å‰é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¸­æ— ç›‘ç£çŸ¥è¯†èå…¥çš„ä¸€äº›è§£å†³æ–¹æ¡ˆ.

ä¸»è¦ä»‹ç»ä»¥ä¸‹ä¸¤ç¯‡å·¥ä½œ:

1. Generalization through Memorization: Nearest Neighbor Language Models. ICLR 2020
2. REALM: Retrieval-Augmented Language Model Pre-Training.

## _k_ NN-LM

> [Generalization through Memorization: Nearest Neighbor Language Models](https://openreview.net/forum?id=HklBjCEKvH). ICLR 2020

è¿™ç¯‡å·¥ä½œæ˜¯ ICLR2020 çš„å·¥ä½œ, å‡ºå‘ç‚¹æ˜¯åˆ©ç”¨ _k_ NN å¢å¼ºé•¿ç¨‹ä¾èµ–(è¿™å·²ç»ä¸æ˜¯é•¿ç¨‹äº†, å«è·¨ç¯‡ç« ä¾èµ–æ›´åˆé€‚ä¸€ç‚¹).

![image](https://cdn.nlark.com/yuque/0/2020/png/104214/1586187950211-30431f66-e154-437e-93ef-3ec3c0ba0b0e.png)

åšæ³•å¾ˆç®€å•. æ‹¿ BERT-base å¯¹æ•°æ®ä¸­çš„æ¯ä¸€ä¸ª token ç”Ÿæˆä¸€ä¸ª(ä¸Šä¸‹æ–‡è¡¨å¾ k-(å…¶ä»– LMs å¯èƒ½æ˜¯åªæœ‰ä¸Šæ–‡), å½“å‰è¯ v) Pair å¯¹, åˆæˆä¸€ä¸ªå¾ˆå¤§çš„é›†åˆ N.

å½“é¢„æµ‹æ—¶éœ€è¦è·å–è¡¨å¾çš„æ—¶å€™, è®¡ç®— N ä¸­æ¯ä¸€ä¸ª k ä¸å½“å‰è¯è®¡ç®—å¾—åˆ°çš„è¡¨å¾ä¹‹é—´çš„è·ç¦», æ­¤å¤„ä½¿ç”¨ L2 è·ç¦»è¿›è¡Œè®¡ç®—.

æœ€åé¢„æµ‹è¯å…³äº x çš„æ¡ä»¶æ¦‚ç‡. ç”±ä¸¤éƒ¨åˆ†ç»„æˆ, åŸå…ˆçš„ LM æ¦‚ç‡å’Œ kNN çš„æ¦‚ç‡, ä¸¤è€…æ’å€¼ä¹‹åè·å¾—æœ€åç»“æœ.

æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸ fine-tune é¢„è®­ç»ƒæ¨¡å‹å‚æ•°, åˆ©ç”¨ FAISS æ¥ä¼˜åŒ–æ£€ç´¢ç©ºé—´(ä¸€ç§ä¼˜åŒ–ç‰ˆçš„ LSH).

![image](https://cdn.nlark.com/yuque/0/2020/png/104214/1586187952486-4027cb66-7bcd-4cf0-94b5-a5b51b6f56d9.png)

ä¸»è¦åœ¨ WikiText 103 å’Œ BookCorpus ä¸Šåšäº†æµ‹è¯•, å…¶ä¸­ WikiText 103 çš„ baseline æ˜¯ Adaptive Input Representations for Neural Language Modeling.

å…¶ä¸»è¦æ€æƒ³æ˜¯æŒ‰ç…§è¯é¢‘åˆ†æˆ N ä¸ªæ¡¶, æ¡¶ä¹‹é—´çš„ embedding size éšç€æŒ‡æ•°å‡å°, å€Ÿé‰´äº† Adaptive Softmax çš„æƒ³æ³•, ä¹‹å‰æ˜¯ WikiText103 çš„ SOTA.

å¯¹æ¯” Transformer-XL çš„ç»“æœ, å¯ä»¥çœ‹å‡º kNN-LM å¸¦æ¥çš„ ppl çš„æå‡è¿˜æ˜¯å¾ˆæ˜æ˜¾çš„.

ç›´è§‚ä¸Šæ¥çœ‹ ppl è¡¨å¾çš„æ˜¯è¯­è¨€æ¨¡å‹æ¦‚ç‡ç­‰å¯èƒ½è¾“å‡ºä¸ªæ•°, æˆ–è€…æ˜¯å¹³å‡æ¦‚ç‡ä¸‹é€‰å–åˆ°æ­£ç¡®è¾“å‡ºéœ€è¦çš„æ¬¡æ•°.

kNN çš„æƒ³æ³•æ˜¾è‘—çš„æå‡ ppl å°±å¯ä»¥ç†è§£ä¸ºåœ¨è¯­ä¹‰ç›¸è¿‘çš„æƒ…å†µä¸‹, å¢å¼ºäº†æ˜¾è‘—çš„å…±ç°æ¨¡å¼, ä»è€Œå‡å°äº†ç­‰æ¦‚ç‡ä¸ªæ•°.

![image](https://cdn.nlark.com/yuque/0/2020/png/104214/1586187953989-c9b278ed-5fef-4f81-8a0b-0cf2eb4e8ce5.png)

å¯¹æ¯”æ‹¿æ•°æ® Fine-tune å’Œæ‹¿æ•°æ®åš dataStore, åœ¨ç”¨ WikiText 103 Fine-tune æ¨¡å‹çš„åŸºç¡€ä¸Šç”¨ WikiText 3B åš dataStore çš„æ•ˆæœæ˜¾è‘—æ¯”æ‹¿æ•°æ® Fine-tune æ•ˆæœå¥½.

è·¨é¢†åŸŸ/zero-shot çš„å®éªŒä¸­ä¹Ÿèƒ½å‘ç°å³ä½¿æ²¡æœ‰åœ¨ BookCorpus ä¸Šå­¦ä¹ è¿‡, åªç”¨ BookCorpus åˆ¶ä½œ DataStore è•´å«çš„ä¿¡æ¯èƒ½æå‡ ppl 14 ä¸ªç‚¹, è™½ç„¶å’Œ fine-tune çš„ç»“æœè¿˜æœ‰å·®è·.

![image](https://cdn.nlark.com/yuque/0/2020/png/104214/1586187955170-54fd30eb-e9a1-4b0f-b674-3a31e0094dc4.png)

è¿˜æµ‹è¯•äº† Transformer ç»“æ„ä¸­ä¸åŒä½ç½®çš„è¾“å‡ºå¯¹äºæœ€åæå‡çš„å½±å“ï¼ˆçœ‹èµ·æ¥è¿™ä¸ªä½œè€…æœ‰ç‚¹é—²

å¾—åˆ°çš„ç»“æœæ˜¯ FFN ä¹‹å‰ LN ä¹‹åè¿™ä¸ªä½ç½®æ•ˆæœæœ€å¥½, ç¬”è€…çš„ç†è§£æ˜¯ MHSA æ›´å…³æ³¨ä¸å½“å‰ sentence æœ¬èº«, FFN æ›´å…³æ³¨ä¸ä¸Šä¸‹æ–‡çš„ memory, ä¸ç»è¿‡ FFN å¯ä»¥æ›´çªå‡ºå½“å‰å¥å­çš„ä¿¡æ¯.

![image](https://cdn.nlark.com/yuque/0/2020/png/104214/1586187956980-6b8564db-d9d5-4705-b184-d8f3345b1675.png)

å½“ç„¶æœ‰äººä¼šæ€€ç–‘ kNN è¿™ç§æ¨¡å¼æ˜¯å¦å’Œ n-gram ç±»ä¼¼, ä½œè€…å¯¹æ¯”äº† n-gram å’Œ kNN çš„ç»“æœ, ä½¿ç”¨ n-gram ä¹‹å performance å˜åŒ–ä¸å¤§.

æœ€åè®¨è®ºäº†ä¸€ä¸‹æ˜¾ç¤ºå­˜å‚¨ memory å’Œéšå¼å­˜å‚¨ memory ä¸¤ç§æƒ…å†µ, è¿™è¾¹ä½œè€…ç”¨å»æ‰ Dropout æ¥æ¨¡æ‹Ÿéšå¼å­˜å‚¨ memoryã€‚ ä»–çš„è®ºç‚¹æ˜¯ loss å·²ç»é™åˆ° 0 äº†è¯´æ˜æ¨¡å‹å·²ç»è•´å«æ‰€æœ‰å¿…è¦çš„çŸ¥è¯†äº†. å¯¹æ¯”ä½¿ç”¨ Dropout, æ•ˆæœå·®å¾ˆå¤š.

å½“ç„¶è¿™ä¸ªé—®é¢˜æ›´å¤šçš„æ˜¯ä¸€ä¸ªå¦‚ä½•åˆ©ç”¨ memory, ä¸Šé¢çš„å®éªŒæœ€èµ·ç å¯ä»¥è¯æ˜ Transformer ç†è®ºä¸Šæ˜¯å…·æœ‰å¾ˆå¼ºçš„ memory èƒ½åŠ›çš„.

å‡ ç‚¹è®¨è®º:

1. kNN-LM çš„æ–¹å¼æœ¬è´¨ä¸Šæ¥è®²è¿˜æ˜¯ä¸€ç§åˆ©ç”¨æ£€ç´¢å¢å¼ºå…±ç°æ¨¡å¼çš„çŸ¥è¯†èå…¥.
2. éœ€è¦æ„å»º dataStore çš„æ•°æ®é›†å’Œæµ‹è¯•é›†ä¹‹é—´å­˜åœ¨è¾ƒå¼ºçš„å…³è”åº¦.
3. å¯¹äºæ—¶é—´å¤æ‚åº¦éƒ¨åˆ†, ä½œè€…åœ¨ openview çš„æ—¶å€™è¯´æ˜å¤§æ¦‚èŠ±è´¹å’Œ fine-tune å·®ä¸å¤šçš„æ—¶é—´, åœ¨ interface é˜¶æ®µä¼šæ¯”çº¯ Transformer è¦æ…¢ä¸€ç‚¹, å¤§æ¦‚ä» 500 tokens per second é™åˆ° 60 tokens per second.
4. ç›®å‰å°šä¸æ¸…æ¥šè¿™ç§æ¨¡å¼æ˜¯å¦èƒ½åœ¨å…¶ä»–ä¸‹æ¸¸ä»»åŠ¡ work, è™½ç„¶ç›´è§‚ä¸Šæ¥æ„Ÿå—åº”è¯¥æ˜¯èƒ½å¢å¼ºè¡¨å¾çš„, è¿˜æ˜¯éœ€è¦æ›´å¤šçš„å®éªŒè¿›è¡ŒéªŒè¯.
5. è¿™ç¯‡æ–‡ç« ä¸­ k å–å¾—æ˜¯ 1024, æ˜¯ä¸€ä¸ªæ¯”è¾ƒå¤§çš„æ•°, ç”»å‡ºæ¥çš„æ›²çº¿å¯ä»¥çœ‹å‡ºéšç€ k çš„å¢å¤§, ppl èƒ½ä¸æ–­çš„ä¸‹é™.

## REALM

> [REALM: Retrieval-Augmented Language Model Pre-Training.](https://arxiv.org/abs/2002.08909)

![image](https://cdn.nlark.com/yuque/0/2020/png/104214/1586187960615-3df26a0f-3916-4ed7-876d-39534251f1ba.png)

è¿™ç¯‡çš„å·¥ä½œæ˜¯åœ¨å‡ ä½ dalao ACL2019 é‚£ç¯‡ [ORQA](https://arxiv.org/abs/1906.00300) çš„åŸºç¡€ä¸Šåšçš„å·¥ä½œ. å…±ä¸€å’Œé€šè®¯ä½œè€…æ˜¯ BERT å››åˆ†ä¹‹äºŒä½œè€….

è¿™ç¯‡æ–‡ç« ä¸»è¦æ˜¯åœ¨ Open domain task ä¸Šåšçš„å·¥ä½œ(æ¯•ç«Ÿæ˜¯è°·æœçš„æ ¸å¿ƒä¸šåŠ¡ ğŸ‘)

å¤§æ¦‚æ€è·¯æ˜¯åˆ©ç”¨ä¸€ä¸ªéšå¼çš„ Retriever æ¥æ‰©å±•è¯­æ–™å¢å¼ºè¯­ä¹‰. $p(y | x)=\sum_{z \in \mathcal{Z}} p(y | z, x) p(z | x)$

å°†é¢„æµ‹è¯ç›¸å¯¹äºä¸Šä¸‹æ–‡çš„æ¡ä»¶æ¦‚ç‡å±•å¼€æˆç›¸å…³ç¯‡ç« åŸºäºä¸Šä¸‹æ–‡çš„æ¦‚ç‡ä¸é¢„æµ‹è¯ç›¸å¯¹äºä¸Šä¸‹æ–‡å’Œç¯‡ç« çš„æ¦‚ç‡ä¹˜ç§¯ä¹‹å’Œ.

- å¯¹äºé¢„è®­ç»ƒæ¨¡å‹æ¥è¯´, x æ˜¯è¢« mask ä¹‹åçš„ sentence, y æ˜¯é¢„æµ‹çš„è¢« mask æ‰çš„é‚£äº›è¯.
- å¯¹äº Fine-tune æ¥è¯´, æ¯”å¦‚è¯´ open-QA x å°±æ˜¯é—®å¥ y åˆ™æ˜¯ç­”æ¡ˆ

å¯¹äº Retriever æ¥è¯´, input å¾—åˆ°çš„ embed å’Œ document å¾—åˆ°çš„ embed çŸ©é˜µç›¸ä¹˜è¿‡ä¸€ä¸ª softmax å°±æ˜¯ z ç›¸å¯¹äº x çš„æ¦‚ç‡è¾“å‡º.

- å…·ä½“æ¥è¯´è¾“å…¥ x çš„ embed, æ˜¯ x è¿™å¥è¯çš„ CLS æŒ‡ç¤ºç¬¦çš„ BERT representation è¾“å‡º, å†ä¹˜ä¸Šä¸€ä¸ªçº¿æ€§çŸ©é˜µ(åœ¨ ORQA ä¸­è¿™ä¸ªçŸ©é˜µèµ·åˆ°ç¼©å°ç»´åº¦çš„ä½œç”¨)
- æ–‡æ¡£çš„ embed åˆ™æ˜¯å°† document çš„ title å’Œ body æ‹¼æ¥èµ·æ¥ç”¨ sep åˆ†å‰², åŒæ ·å– CLS çš„è¾“å‡ºå†ä¹˜ä¸Šä¸€ä¸ªçº¿æ€§çŸ©é˜µ
- è¿™è¾¹è€ƒè™‘ä¸¤ä¸ª Embed ç›¸ä¹˜, æ„Ÿè§‰æ›´å¤šçš„é¢„å…ˆå¤„ç†çš„è§’åº¦.

$p(z | x)=\frac{\exp f(x, z)}{\sum_{z^{\prime}} \exp f\left(x, z^{\prime}\right)}$

$f(x, z)=\text { Embed }_{\text {input }}(x)^{\top} \text { Embed }_{\text {doc }}(z)$

$\text { Embed }_{input}(x)=\mathbf{W}_{\text {input }} \operatorname{BERT}_{\text {CLS }}\left(\text { join }_{\text {BERT }}(x)\right)$

$\text { Embed }_{\text {doc }}(z)=\mathbf{W}_{\text {doc }} \operatorname{BERT}_{\text {CLS }}\left(\text { join }_{\text {BERT }}\left(z_{\text {title }}, z_{\text {body }}\right)\right)$

çŸ¥è¯†å¢å¼ºç¼–ç å™¨çš„è®¡ç®—åˆ†ä¸ºé¢„è®­ç»ƒå’Œå¾®è°ƒä¸¤ä¸ªæ¨¡å¼

- Pre-trained.
  - j ä½ç½®é¢„æµ‹ä¸º y_j çš„æ¦‚ç‡ä¹˜ç§¯
  - è€Œ y_j åœ¨ z, x ä¸‹çš„æ¦‚ç‡ä¸æ‹¼æ¥ x ä¸ z çš„æ­£æ–‡éƒ¨åˆ†å¾—åˆ°çš„åœ¨ Mask_j ä½ç½®çš„è¡¨å¾çš„æŒ‡æ•°æ¬¡å‘ˆæ­£ç›¸å…³.
- Fine-tune
  - n ä¸ª span çš„è¡¨å¾ä¹‹å’Œ
  - span çš„è¡¨å¾åˆ™ä¸ºå°† x ä¸ z çš„æ­£æ–‡éƒ¨åˆ†æ‹¼æ¥åœ¨ä¸€èµ·åœ¨ span start end ä¸¤ä¸ªä½ç½®çš„ representations è¾“å‡º concat åœ¨ä¸€èµ·, ç„¶åè¿‡ä¸€ä¸ª MLP ä¹‹å’Œå†å–æŒ‡æ•°æ¬¡.

$$
\begin{aligned} p(y | z, x) &=\prod_{j=1}^{J_{x}} p\left(y_{j} | z, x\right) \\ p\left(y_{j} | z, x\right) & \propto \exp \left(w_{j}^{\top} \operatorname{BERT}_{\operatorname{MASK}(j)}\left(\text { join }_{\mathrm{BERT}}\left(x, z_{\mathrm{body}}\right)\right)\right) \end{aligned}
$$

å½“ç„¶ z å¯¹äº x çš„åˆ†å¸ƒæ˜¯ä¸€ä¸ªé•¿å°¾åˆ†å¸ƒ, å¤§éƒ¨åˆ† z å¯¹äº x éƒ½æ˜¯æ²¡ç”¨çš„, top-K æ˜¯ä¸€ä¸ªå¾ˆæ˜¾ç„¶çš„æ€è·¯.
å†åˆ©ç”¨ LSH è¿™ç§ MIPS æ–¹æ³•å¯¹æœç´¢ç©ºé—´è¿›è¡Œä¼˜åŒ–.
LSH çš„æ€è·¯å¤§æ¦‚å°±æ˜¯é«˜ç»´ç©ºé—´çš„æŠ•å½±èƒ½ä¿ç•™ç›¸è¿‘çš„å…³ç³», ä½†æŠ•å½±ä¸­ç›¸è¿‘ä¸èƒ½ä¿è¯é«˜ç»´ç©ºé—´ä¸­ç›¸è¿‘, æ‰€ä»¥ä¸€èˆ¬ä¼šä½¿ç”¨å¤šä¸ª Hash å‡½æ•°è”åˆåˆ¤æ–­.
æœ€è¿‘ LSH å‡ºé•œç‡è¿˜è›®é«˜çš„, Reformer ä¹‹ç±»çš„éƒ½æœ‰æåˆ°.

å› ä¸ºä½¿ç”¨äº† LSH, å°±éœ€è¦é¢„è®¡ç®— document çš„ Embed, ä½†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿™ä¸ª Embed ä¹Ÿä¼šå˜, è¿™è¾¹å°±é‡‡ç”¨äº†ä¸€ä¸ªå»¶è¿Ÿæ›´æ–°çš„æƒ³æ³•, å®é™…ä¸­æ¯éš” 500step æ›´æ–°ä¸€æ¬¡ document Embed å‚æ•°.
è¿™éƒ¨åˆ†æ›´æ–°çš„åªæ˜¯ Top-K çš„å‚æ•°.
ä½œè€…è®¤ä¸ºç»è¿‡é¢„è®­ç»ƒ Document çš„ Embed å·²ç»å¾ˆå¥½äº†, åœ¨ Fine-tune é˜¶æ®µ Document çš„ Embed å°±å›ºå®šäº†ä¸å†è¿›è¡Œè®­ç»ƒäº†.

![image](https://cdn.nlark.com/yuque/0/2020/png/104214/1586187962425-9a4993f5-0bc0-4d86-8637-87ac68d15077.png)

ç„¶åè¿˜åŠ äº†ä¸€äº› tricks ä¸Šå»

1. Span level çš„ Mask. ç”¨äº†åœ¨ CoNLL-03 ä¸Šé¢ fine-tune çš„ BERT-base ä½œä¸º chuck å·¥å…·æ¥è·å– entity çš„è¾¹ç•Œ. åé¢ç»“æœæ˜¾ç¤ºè¿™ä¸ªæ“ä½œè‡³å…³é‡è¦.(å…¶å®è§‰å¾— SpanBERT é‚£ä¸ªæ“ä½œæœ‰ç‚¹è¿·)
2. è€ƒè™‘åˆ°æœ‰äº› sentence ä¸éœ€è¦å…¶ä»– document è¾…åŠ©, åœ¨ Document ä¸­å¢åŠ ç©º Document.
3. å½“ x å¥å­åœ¨æ£€ç´¢æ—¶, å»é™¤ x å¥å­æ‰€åœ¨çš„ Document, é¿å…å˜æˆå•çº¯çš„å­¦ä¹ åˆ°è¯å¥åŒ¹é….
4. ç”±ä¸Šé¢çš„æè¿°, æˆ‘ä»¬å¯ä»¥çœ‹å‡º, è¿™æ˜¯ä¸€ä¸ªå¾ˆçœ‹é‡åˆå§‹åŒ–è¿‡ç¨‹çš„æ¨¡å‹.å½“ç„¶ä¹Ÿå¯ä»¥ç†è§£ä¸ºå°±æ˜¯åœ¨ pre-trained åŸºç¡€ä¸Š pre-trained, çœ‹ lr ä¹Ÿæ˜¯.
   - å¯¹äº Retriever åˆ©ç”¨ Inverse Cloze Task (ICT)ä»»åŠ¡. ICT ä»»åŠ¡æ˜¯å°† document æŒ–å»ä¸€äº›å¥å­, ç„¶ååˆ¤æ–­å¥å­æ˜¯å¦å±äºè¿™ä¸ªæ–‡æ¡£. ICT å¸®åŠ©æ¨¡å‹è·å¾—é™¤è¯åŒ¹é…ä¹‹å¤–è¯­ä¹‰åŒ¹é…çš„èƒ½åŠ›.
   - å¯¹äº Knowledge Augment Encoder æ¥è¯´, ç›´æ¥ä½¿ç”¨ BERT-based.

ä½œè€…é™¤äº†æå‡ºä»¥ä¸Šæ¨¡å‹, è®­ç»ƒæ–¹æ³•ä¹‹å¤–, è¿˜è¯•å›¾è§£é‡Š Retriever å­¦ä¹ åˆ°çš„å†…å®¹.

$$
\begin{aligned} \nabla \log p(y | x) &=\sum_{z \in \mathcal{Z}} r(z) \nabla f(x, z) \\ r(z) &=\left[\frac{p(y | z, x)}{p(y | x)}-1\right] p(z | x) \end{aligned}
$$

logp(y|x)å¯¹ Retriever å‚æ•°æ±‚åå¯¼å¯ä»¥å¾—åˆ°[(è¿™ä¸€éƒ¨åˆ†æ¨åˆ°å¯ä»¥å‚è€ƒæˆ‘åœ¨ pdf ä¸­æ‰‹æ¨çš„è¿‡ç¨‹)](https://www.yuque.com/preview/yuque/0/2020/pdf/104214/1586187444506-2c27d9ef-d29a-4b2f-9581-479901113e1e.pdf)

ç›¸å½“äºæ¨¡å‹çš„æ¢¯åº¦æ˜¯å‘é‚£äº›åŠ ä¸Š z æ¡ä»¶æ¦‚ç‡å˜å¤§çš„æ ·æœ¬.
è¿™ä¹Ÿå¾ˆç¬¦åˆç›´è§‚æ„Ÿå—, Retriever å­¦åˆ°çš„æ›´å¤šçš„æ˜¯ç­›é€‰èƒ½æå‡ performance çš„æ–‡æ¡£çš„èƒ½åŠ›.

å¦‚æœä½¿ç”¨ DrQA çš„æ€è·¯, ä¸Šå¼çš„å¯¼æ•°å¯åŒ–ä½œå‚è€ƒæ ·æœ¬çš„æ¢¯åº¦.

å®éªŒæ˜¯ä¸»è¦åœ¨ Open-QA ä¸‰ä¸ªæ•°æ®é›†ä¸Šåšäº†æµ‹è¯•.
ç›¸å¯¹äºå¼º baseline ORQA å’Œ T5 çš„ 11b ä¸¤ä¸ª baseine éƒ½æœ‰æ˜¾è‘—çš„æå‡.

![image](https://cdn.nlark.com/yuque/0/2020/png/104214/1586187964608-682b245d-922f-4a60-84c9-8983719af770.png)

Ablation å®éªŒå¯ä»¥çœ‹å‡ºå‚æ•° Fine-tune å½±å“ä¸æ˜¯ç‰¹åˆ«å¤§, mask æœºåˆ¶å½±å“ç‰¹åˆ«å¤§, åŸºæœ¬ä¸ŠåŒ…æ‹¬äº†æ‰€æœ‰çš„æå‡ç‚¹.
æˆ‘çš„ç†è§£æ˜¯ random Mask å®¹æ˜“ä½¿å¾— sentence å¤±å»åŸæœ¬çš„è¯­ä¹‰, ä»è€Œå¯¹ Retriever äº§ç”Ÿå·¨å¤§çš„å½±å“.

![image](https://cdn.nlark.com/yuque/0/2020/png/104214/1586187966387-559dd44f-c2d7-4357-870d-10b0c0307fbe.png)

åŒæ ·çš„, è®¾è®¡äº†ä¸€ä¸ª RU æŒ‡æ ‡, æ¥ probing Retriever å¯¹æ¨¡å‹çš„å½±å“.

$\mathrm{RU}(z | x)=\log p(y | z, x)-\log p(y | \varnothing, x)$

![image](https://cdn.nlark.com/yuque/0/2020/png/104214/1586187967534-c1b4dc2b-0740-4ca4-8e45-316be2a95080.png)

![image](https://cdn.nlark.com/yuque/0/2020/png/104214/1586187958825-1374ed91-ddbf-4602-9015-7e053ae013d0.png)

å‡ ç‚¹è®¨è®º:

1. çœ‹èµ·æ¥å‚æ•°åˆå§‹åŒ–å¯¹æ¨¡å‹çš„æ•ˆæœå½±å“å¾ˆå¤§.
2. éšå˜é‡çš„æ–¹å¼çœ‹èµ·æ¥å¾ˆä¼˜é›…, å¾—åˆ°ä¸¤ä¸ªå‰¯äº§ç‰©: retriever å’Œ æ–‡æ¡£çº§çš„ representations.
3. æ³¨æ„åˆ° Mask ç­–ç•¥å¯¹ç»“æœå½±å“å¾ˆå¤§, è¿™æ˜¯ä¸€ä¸ªéšæ‚£, æœ€å¥½èƒ½æœ‰ä¸€ä¸ª ORQA + mask çš„å¯¹æ¯”è¯•éªŒ.
4. è¿™æ˜¯ä¸€ç§åˆ©ç”¨æ— ç›‘ç£çš„æ–¹å¼å°†éç»“æ„åŒ–æ•°æ®ä¸­çš„çŸ¥è¯†èå…¥åˆ° LMs ä¸­çš„ç­–ç•¥, çœ‹èµ·æ¥æ¯”è¾ƒè‡ªç„¶.ç©¶ç«Ÿæ˜¯ç»“æ„åŒ–çš„æ–¹æ³•æ›´å¥½ä¸€ç‚¹è¿˜æ˜¯éç»“æ„åŒ–çš„æ›´å¥½ä¸€ç‚¹å‘¢ï¼Ÿ
5. å¯ä»¥é€šè¿‡æ›´æ¢è¯­æ–™æ¥è¾ƒå¿«çš„æ›´æ–°è¯­è¨€æ¨¡å‹ä¸­çš„ä¿¡æ¯, ä½†æ˜¯å¯¹äºâ€œThatcherâ€ for â€œ\_\_ is the prime minister of United Kingdom.â€æ¨¡å‹è¿˜æ˜¯å›ç­”é”™äº†.ä¸ªäººçš„ç†è§£è¿™ç§æ–¹å¼æ›´å¤šçš„è¿˜æ˜¯å¢å¼ºå…±ç°å…³ç³»çš„ç­–ç•¥, å½“ç„¶è¿™ä¸ªæ—¶å€™ç»“æ„åŒ–æ•°æ®å¯èƒ½å°±æœ‰ä¼˜åŠ¿. æˆ‘è§‰å¾—é™¤äº†ä¸‰å…ƒç»„çš„æ–¹å¼ä¹‹å¤–, å¯¹äºå®æ•ˆæ€§å¾ˆå¼ºçš„, æ˜¯ä¸æ˜¯å¯ä»¥åªç”¨æœ€è¿‘çš„è¯­æ–™è¿›è¡Œè®­ç»ƒ, è¿™æ ·çš„æ•ˆæœå¯èƒ½ä¼šæ›´å¥½ä¸€ç‚¹.

## æ€»ç»“

å¼±ç›‘ç£æˆ–è€…æ— ç›‘ç£æ‹¥æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›, å¯¹äºçŸ¥è¯†èå…¥è¿™ä¸ªé—®é¢˜æ¥è¯´è¿™ä¸¤ç¯‡å·¥ä½œå°è¯•ä½¿ç”¨ kNN å’Œéšå˜é‡çš„æ–¹å¼èå…¥éç»“æ„åŒ–çš„ä¿¡æ¯, å…·æœ‰å¼€åˆ›æ€§.

æ°´å¹³æœ‰é™, æ¬¢è¿è®¨è®º.

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css"/>
